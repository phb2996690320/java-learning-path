---
url: https://blog.csdn.net/qq_40991313/article/details/130279363
title: 【Java 面试题汇总】Redis 篇（2025 版）_java redis 面试题 - CSDN 博客
date: 2025-02-20 13:45:53
tag: 
summary: 
---
**导航：**

[【Java 笔记 + 踩坑汇总】Java 基础 + JavaWeb+SSM+SpringBoot+SpringCloud + 瑞吉外卖 / 谷粒商城 / 学成在线 + 设计模式 + 面试题汇总 + 性能调优 / 架构设计 + 源码解析](https://blog.csdn.net/qq_40991313/article/details/126646289?csdn_share_tail=%7B%22type%22%3A%22blog%22%2C%22rType%22%3A%22article%22%2C%22rId%22%3A%22126646289%22%2C%22source%22%3A%22qq_40991313%22%7D "【Java笔记+踩坑汇总】Java基础+JavaWeb+SSM+SpringBoot+SpringCloud+瑞吉外卖/谷粒商城/学成在线+设计模式+面试题汇总+性能调优/架构设计+源码解析")

**目录**

[1、说说你对 Redis 的了解](#t0)

[2、说说 Redis 的单线程架构](#t1)

[3、详细的说说 Redis 的数据类型](#t2)

[4、请你说说 Redis 数据类型中的 zset, 它和 set 有什么区别？底层是怎么实现的？](#t3)

[5、说说 Redis 的持久化策略](#t4)

[6、说说缓存穿透、击穿、雪崩的区别](#t5)

[7、如何利用 Redis 实现一个分布式锁？](#t6)

[8、Redis 如何与数据库保持双写一致性](#t7)

[9、说说 Redis 的主从同步机制](#t8)

[10、如何实现 Redis 高可用（主从哨兵集群）](#t9)

[11、为什么 Redis 集群中，哈希槽数量是 16384？](#t10)

[12、什么是一致性哈希算法？Redis 为什么使用哈希槽而非一致性哈希算法？](#t11)

[13、Redis 为什么使用哈希槽而不用一致性哈希？](#t12)

[14、说说 Redis 的缓存淘汰策略](#t13)

[15、Redis 事务是否满足 ACID？](#t14)

[16、如何排查 Redis 中的慢查询？](#t15)

### 1、说说你对 Redis 的了解

**得分点**

Redis 概念（数据类型、读写性能）、Redis 读写为什么不采用多线程？为什么单线程还读写性能这么高？Redis 的瓶颈、功能、事务、数据类型、应用场景、持久化机制

**概念：**

*   **数据库：**Redis 是一款基于键值对的、线程安全的 NoSQL 数据库；
*   **内存读写性能：**它在内存中读写性能非常高，每秒可以处理超过百万次的读写操作。
*   **服务端线程安全，客户端线程不安全：**Redis 服务端是线程安全的，永远只有主线程一个线程进行读写，不需要任何的同步机制。虽然 Redis6.0 增加了多线程的模型，但多线程目的只是为了处理网络的 IO 事件，读写指令的执行依然由主线程自己处理。Redis 客户端层面线程不安全，要引入原子指令（例如 INCR 是给数值原子性加 1）、分布式锁、lua 脚本保证 Redis 的原子操作。

**Redis 读写为什么不采用多线程？** 

*   **CPU 不是瓶颈：**Redis 在内存中读写性能非常高，CPU 不是 Redis 的瓶颈，无需使用多线程。
*   **担心加锁影响性能：**多线程情况下，想实现线程安全必须加锁，加锁将极大地影响性能。

**为什么单线程还读写性能这么高？**

*   **基于内存：**Redis 是基于内存的，内存的读写速度非常快；
*   **上下文切换：**单线程避免了不必要的上下文切换和竞争条件；
*   **IO 多路复用：**底层采用 NIO（非阻塞 IO），NIO 采用 IO 多路复用技术，一个线程通过多路复用器处理多个连接。IO 多路复用技术选用 epoll 调用模型，红黑树存所有事件，链表存就绪事件。epoll_wait 函数链表，通知应用程序读写操作。

**Redis 的瓶颈：**

*   **内存：**因为读写在内存中进行，内存大小会影响 Redis 性能。可以通过加内存、读写分离优化性能。
*   **网络带宽：**网络 IO 是 Redis 最大瓶颈，也就是客户端和服务端之间的网络传输延迟。Redis6.0 引入了网络 IO 多线程模型，提高了性能瓶颈。

**功能：**键过期、事务、lua 脚本（基于 C 语言，性能快）、持久化机制。

**事务：**

*   **实现方式：**MULTI（开启事务，将命令都放进队列里），EXEC（执行事务），DISCARD（取消事务，清空队列）。
*   **不支持回滚：**在语法正确的情况下，Redis 事务一定会执行成功。只有语法错误时才会导致事务失败，而语法问题应该在开发时就避免，所以为了提高性能，Redis 事务不支持回滚。事务是一个原子操作，要么全部执行，要么全不执行。
*   **不完全满足 ACID 特性：**Redis 只满足隔离性和持久性，不满足原子性和一致性。
    *   **原子性：**事务的所有操作，要么全部成功，要么全部失败。Redis 不满足原子性，单个 Redis 命令的执行是原子性的，但事务失败后无法回滚。
    *   **一致性：**事务前后，数据库的约束没有被破坏，保持前后一致。Redis 连约束这个概念都没有。
    *   **隔离性：**操作同一资源的并发事务之间相互隔离，不会互相干扰。Redis 满足隔离性，因为 redis server 是单线程的，串行化执行事务，肯定是满足隔离性的。
    *   **持久性：**事务的结果最终一定会持久化到数据库，宕机等故障也无法影响。Redis 在开启 aof 并指定立刻持久化命令时，满足持久性。rdb 模式会丢失部分数据，不满足持久性。

**数据类型：** string、hash、 list、set（集合）、zset（有序集合）

**应用场景：**缓存热点且不经常修改的数据、计数器、限时业务、分布式锁（set nx）、队列等。

**持久化机制：**

*   **数据备份机制 RDB（默认）：数据**每隔一段时间写进磁盘 rdb 文件，故障后从文件读。可以在 redis.conf 配置多少秒内多少 key 修改时自动 bgsave。占 CPU 和内存但恢复快，不能恢复完整数据。save 命令是主进程立即执行一次 RDB，其他所有命令进程阻塞。bgsave 是子进程 fork 主进程，阻塞并拷贝一份主进程的页表（虚拟内存到物理内存的映射关系），然后子进程写数据到 rdb 文件，主进程继续处理用户请求，
*   **追加文件机制 AOF：**命令**日志**按指定频率（默认立刻，在 redis.conf 配置为缓存一秒）写进磁盘 aof 文件，可以按条件（redis.conf 配置，比上次重写 aof 文件超过多少百分比时自动重写、aof 文件超过多大自动重写）自动重写 aof 文件中的命令（多次更新同一数据只有最近一次更新有效），故障后从文件读命令恢复数据。不占 CPU 和内存占 IO，能恢复完整或故障 1s 前的数据但恢复慢。

**标准回答**

**NIO：**

NIO：非阻塞 I/O 模型，同步非阻塞，一个线程通过多路复用器可以处理多个连接（即请求）。客户端发送的连接会通过通道注册到多路复用器上，多路复用器轮询所有就绪的通道处理 IO。访问数据都是通过缓冲区操作。

三个核心组件：Buffer（缓冲区）、Channel（通道）、Selector（多路复用器）。

非阻塞：一个连接不做事，线程不会被阻塞，可以轮询处理其他连接。

**IO 多路复用：**一个线程处理多个 IO 操作。

一个线程中同时监听多个文件句柄（文件描述符，标记已打开文件的正整数），一旦有文件就绪（可读或可写）时，会通知应用程序进行读写操作。没有文件句柄就绪时就会阻塞应用程序，从而释放出 CPU 资源。

**epoll 调用：**底层的数据结构为红黑树加链表，红黑树存所有事件，链表存就绪事件，内核查红黑树将就绪事件插入链表，epoll 调用通过 epoll_wait 函数返回内核的就绪事件列表，通知应用程序读写操作。回调效率高（O(1)），不会随着文件描述符个数增多导致性能下降，不限制文件描述符个数。缺点是只能在 Linux 工作。

Redis 是一款**基于键值对的 NoSQL 数据库**，与其他键值对数据库不同的是，Redis 中拥有 string（字符串）、hash（哈希）、 list（列表）、set（集合）、zset（有序集合）、Bitmaps（位图）、 HyperLogLog、GEO（地理信息定位）等**多种数据结构**，这给 Redis 带来了满足多种应用场景的能力，而且，Redis 将所有数据放到**内存**中的做法让它的**读写性能**十分惊人。不仅如此，Redis 的**持久化机制**保证了在发生类似断电，机械故障等情况时，内存中的数据不会丢失。此外 Redis 还提供了**键过期**、发布订阅、**事务**、流水线、**Lua 脚本**等多个附加功能。总之，在合适的情况下使用 Redis 会大大增强系统的性能，减少开发人员工作量。

持久化机制：RDB、AOF 

**RDB** 全称 Redis Database Backup file（Redis 数据备份文件，backup 译为备份，支援），也被叫做 Redis 数据快照。简单来说就是把内存中的所有**数据都记录到磁盘**中。当 Redis 实例故障重启后，**从磁盘读取快照文件**，恢复数据。快照文件称为 RDB 文件，默认是保存在当前运行目录。缺点是耗时、两次 RDB 间隔时间长，会丢失数据。

**AOF** 全称为 Append Only File（追加文件）。Redis 处理的每一个写命令都会记录在 AOF 文件，可以看做是**命令日志文件**。因为是记录命令，AOF 文件会比 RDB 文件大的多。而且 AOF 会记录对同一个 key 的多次写操作，但只有最后一次写操作才有意义。通过执行 bgrewriteaof 命令，可以让 AOF 文件执行重写功能，用最少的命令达到相同效果。

**加分回答 - 适合 Redis 使用的场景：**

- **热点数据的缓存：**redis 访问速度块、支持的数据类型丰富，很适合用来存储热点数据。

- **限时业务：**redis 中可以使用 expire 命令设置一个键的生存时间，到时间后 redis 会删除它。因此，Redis 在限时业务中的表现很亮眼。

**- 计数器：**incrby 命令可以实现**原子性的递增**，所以可以运用于高并发的秒杀活动、分布式序列号的生成。

- **排行榜：**关系型数据库在排行榜方面查询速度普遍偏慢，所以可以借助 redis 的 SortedSet 进行**热点数据的排序**。

**- 分布式锁：**这个主要利用 redis 的 setnx 命令进行，在后面的如何用 Redis 实现一个分布式锁中会进行详解。

- 延时操作：redis 自 2.8.0 之后版本提供 Keyspace Notifications 功能，允许客户订阅 Pub/Sub 频道，以便以某种方式接收影响 Redis 数据集的事件。

- 分页查询、模糊查询：edis 的 set 集合中提供了一个 zrangebylex 方法，通过 ZRANGEBYLEX zset - + LIMIT 0 10 可以进行分页数据查询，其中 - + 表示获取全部数据；rangebylex key min max 这个就可以返回字典区间的数据可以利用这个特性可以进行模糊查询功能。

- **点赞，好友等相互关系的存储：**Redis set 对外提供的功能与 **list** 类似是一个列表的功能，特殊之处在于 **set 是可以自动排重**的，我们可以通过这一点实现类似共同好友等功能。

**- 队列：**由于 redis 有 **list push 和 list pop** 这样的命令，所以能够很方便的执行队列操作。

### 2、说说 Redis 的单线程架构

**得分点**

服务端线程安全，为什么不采用多线程、为什么单线程还读写性能这么高？Redis 的瓶颈

**服务端线程安全，客户端线程不安全：**Redis 服务端是线程安全的，永远只有主线程一个线程进行读写，不需要任何的同步机制。虽然 Redis6.0 增加了多线程的模型，但多线程目的只是为了处理网络的 IO 事件，读写指令的执行依然由主线程自己处理。Redis 客户端层面线程不安全，要引入原子指令（例如 INCR 是给数值原子性加 1）、分布式锁、lua 脚本保证 Redis 的原子操作。 

**Redis 读写为什么不采用多线程？** 

*   **CPU 不是瓶颈：**Redis 在内存中读写性能非常高，CPU 不是 Redis 的瓶颈，无需使用多线程。
*   **担心加锁影响性能：**多线程情况下，想实现线程安全必须加锁，加锁将极大地影响性能。

**为什么单线程还读写性能这么高？**

*   **基于内存：**Redis 是基于内存的，内存的读写速度非常快；
*   **上下文切换：**单线程避免了不必要的上下文切换和竞争条件；
*   **IO 多路复用：**底层采用 NIO（非阻塞 IO），NIO 采用 IO 多路复用技术，一个线程通过多路复用器处理多个连接。IO 多路复用技术选用 epoll 调用模型，红黑树存所有事件，链表存就绪事件。epoll_wait 函数链表，通知应用程序读写操作。

**Redis 的瓶颈：**

*   **内存：**因为读写在内存中进行，内存大小会影响 Redis 性能。可以通过加内存、读写分离优化性能。
*   **网络：**网络 IO 是 Redis 最大瓶颈，也就是客户端和服务端之间的网络传输延迟。Redis6.0 引入了网络 IO 多线程模型，提高了性能瓶颈。

**标准回答**

Redis 的**网络 IO 和键值对读写是由一个线程来完成**的，但 Redis 的其他功能，例如持久化、异步删除、集群数据同步等操作依赖于其他线程来执行。单线程可以简化数据结构和算法的实现，并且可以避免线程切换和竞争造成的消耗。但要注意如果**某个命令执行时间过长**，会造成其他命令的**阻塞**。

Redis 采用了 **io 多路复用机制**，这带给了 Redis 并发处理大量客户端请求的能力。它允许**单个线程同时监听多个 IO 事件**，并在有事件发生时及时通知程序进行相应的处理。常见的 IO 多路复用技术包括：select、poll 和 epoll 等。

Redis 单线程高性能的原因：

因为对服务端程序来说，线程切换和锁通常是性能杀手，而单线程**避免了线程切换和竞争所产生的消耗**。另外 Redis 的大部分操作是在**内存**上完成的，这是它实现高性能的一个重要原因；Redis 还采用了 **IO 多路复用机制**，使其在网络 IO 操作中能并发处理大量的客户端请求，实现**高吞吐率**。

**加分回答**

Redis 的单线程主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的。而 Redis 的其他功能，如持久化、异步删除、集群数据同步等，则是依赖其他线程来执行的。所以，说 Redis 是单线程的只是一种习惯的说法，事实上它的底层不是单线程的。

### 3、详细的说说 Redis 的数据类型

**得分点**

Redis5 种数据结构

**字符串 (string)：**存储字符串、数字和二进制数据，最大存 2M。底层数据结构是二进制安全（传输时不会被篡改、破译）、可以动态分配空间和回收内存的简单动态字符串 SDS（Simple Dynamic String），

*   存字符串 时，Redis 会将其视为二进制安全的字符序列。
*   存储数字时，Redis 会将其转换成 64 位有符号整数或双精度浮点数。
*   存储二进制数据时，Redis 会将其视为字节数组，并以原始形式进行存储，不会进行任何编码格式转换。 

**哈希 (hash)：**value 是键值对类型，可用于存对象。底层是压缩列表和哈希表。

**列表 (list)：**元素有序可重复。底层是双向链表和压缩列表。**应用场景：**支持范围查询的栈（lpush+lpop）、队列（lpush+rpop）、阻塞队列（lpush+brpop）。**命令：**lpush,lpop,blpop,rpop,brpop（移除最右元素，若没元素则阻塞直到有元素去移除或超时）,lrange,llen。

**集合 (set)：**元素无序不可重复，既不自然有序也不插入有序；支持多个 set 求交集、并集、差集。底层是哈希表和整数数组。命令：sadd,smembers,sismember,scard(获取成员数),sinner,sunion,sdiff,srem（移除）。**应用场景：**

*   **统计去重后数据量：**例如网站访问量、点赞量，将每个访问者的 ip 放在 set 里，自动去重，通过 scard 获取访问量。
*   **判断某元素是否在集合里：**例如文章浏览记录，某用户每阅读完一篇文章，就将文章 id 加到 set 里，通过 sismember 判断某文章是否被浏览过。
*   **集合运算：**key1 记录小明的所有兴趣爱好，key2 记录小李的兴趣爱好，通过交集并集差集，实现用户兴趣爱好的比较、推荐。

**有序集合 (zset)：**元素有序不可重复，有序依据是每个元素的设置一个分数，按分数从小到大排序，分数相等时按照元素字典序排序。可以通过 zincryby 命令给指定成员加分数。底层是压缩列表和跳跃表。命令：zadd,zrange,zincrby,zrem。**应用场景：**

*   **排行榜：**例如积分榜、粉丝数量磅，元素是每个用户 id，分数是积分、粉丝数。
*   **时间轴：**例如用户所有文章按发布时间排序；元素是该用户的每篇文章，分数是文章发布时间。

list 和 zset 支持范围查询，set 不支持范围查询。 

**标准回答 1**

Redis 主要提供了 5 种数据结构：字符串 (string)、哈希 (hash)、列表 (list)、集合 (set)、有序集合 (zset)。

Redis 还提供了 Bitmap、HyperLogLog、Geo 类型，但这些类型都是基于上述核心数据类型实现的。5.0 版本中，Redis 新增加了 **Streams 数据类型**，它是一个功能强大的、支持多播的、可持久化的消息队列。

**string** 可以存储**字符串、数字和二进制数据**，除了值可以是 String 以外，所有的键也可以是 string，string 最大可以存储大小为 **2M** 的数据。

**list** 保证数据线性有序且元素可重复，它支持 lpush、blpush、rpop、brpop 等操作，可以当作**简单的消息队列**使用，一个 list 最多可以存储 **2^32-1** 个元素

**hash** 的值本身也是一个键值对结构，最多能存储 2^32-1 个元素。

**set** 是无序不可重复的，它支持**多个 set 求交集、并集、差集**，适合实现共同关注之类的需求，一个 set 最多可以存储 2^32-1 个元素

**zset** 是有序不可重复的，它通过给**每个元素设置一个分数来作为排序的依据**，一个 zset 最多可以存储 2^32-1 个元素。

**加分回答 - 编码**

**每种类型支持多个编码**，每一种编码采取一个特殊的结构来实现 各类数据结构内部的编码及结构：

string：编码分为 int、raw、embstr；int 底层实现为 long，当数据为整数型并且可以用 long 类型表示时可以用 long 存储；embstr 底层实现为占一块内存的 SDS 结构，当数据为长度不超过 32 字节的字符串时，选择以此结构连续存储元数据和值；raw 底层实现为占两块内存的 SDS，用于存储长度超过 32 字节的字符串数据，此时会在两块内存中分别存储元数据和值。

list：编码分为 ziplist、linkedlist 和 quicklist（3.2 以前版本没有 quicklist）。ziplist 底层实现为压缩列表，当元素数量小于 2 且所有元素长度都小于 64 字节时，使用这种结构来存储；linkedlist 底层实现为双端链表，当数据不符合 ziplist 条件时，使用这种结构存储；3.2 版本之后 list 一般采用 quicklist 的快速列表结构来代替前两种。

hash：编码分为 ziplist、hashtable 两种，其中 ziplist 底层实现为压缩列表，当键值对数量小于 2，并且所有的键值长度都小于 64 字节时使用这种结构进行存储；hashtable 底层实现为字典，当不符合压缩列表存储条件时，使用字典进行存储。

set：编码分为 inset 和 hashtable，intset 底层实现为整数集合，当所有元素都是整数值且数量不超过 2 个时使用该结构存储，否则使用字典结构存储。

zset：编码分为 ziplist 和 skiplist，当元素数量小于 128，并且每个元素长度都小于 64 字节时，使用 ziplist 压缩列表结构存储，否则使用 skiplist 的字典 + 跳表的结构存储。

![](<assets/1740030353812.png>)

**标准回答 2**

Redis 主要提供了 5 种数据结构：字符串 (String)、哈希 (Hash)、列表 (List)、集合 (set)、有序集合 (zset)。

**String 是一组字节**。在 Redis 数据库中，字符串是**二进制安全的**。这意味着它们具有已知长度，并且不受任何特殊终止字符的影响。可以在一个字符串中存储最多 2 兆字节的内容。

Redis 列表定义为字符串列表，按插入顺序排序。可以将元素添加到 Redis 列表的头部或尾部。列表的最大长度为 232 – 1 个元素（超过 40 亿个元素）。

**哈希**是键值对的集合。在 Redis 中，哈希是**字符串字段和字符串值之间的映射**。因此，它们适合表示对象。每个哈希可以存储多达 232– 1 个字段 - 值对。

集合（set）是 Redis 数据库中的无序字符串集合。在 Redis 中，在 redis sorted sets 里面当 items 内容大于 64 的时候同时使用了和 skiplist 两种设计实现。这也会为了排序和查找性能做的优化。关于时间复杂度：添加和删除都需要修改 skiplist，所以复杂度为 O(log(n))。

但是如果仅仅是查找元素的话可以直接使用 hash，其复杂度为 O(1) ，其他的 range 操作复杂度一般为 O(log(n))，当然如果是小于 64 的时候，因为是采用了 ziplist 的设计，其时间复杂度为 O(n) 集合中的最大成员数为 232-1 个元素（超过 40 亿个元素）。

Redis 有序集合类似于 Redis 集合，也是一组非重复的字符串集合。但是，排序集的每个成员都与一个分数相关联，该分数用于获取从最小到最高分数的有序排序集。虽然成员是独特的，但可以重复分数。

**加分回答**

Redis 还提供了 Bitmap、HyperLogLog、Geo 类型，但这些类型都是基于上述核心数据类型实现的。5.0 版本中，Redis 新增加了 Streams 数据类型，它是一个功能强大的、支持多播的、可持久化的消息队列。

### 4、请你说说 Redis 数据类型中的 zset, 它和 set 有什么区别？底层是怎么实现的？

**得分点**

有序无序、底层存储结构、zset 底层不使用红黑树的原因

**zset（有序集合） ：**元素有序不可重复，每个元素关联一个可重复的 double 类型的分数，Redis 是通过这个分数对元素排序的。分数可重复，元素

**zset 底层存储结构：**ziplist（压缩列表）或 skiplist（跳跃表）。

元素数量小于 128 个，且每个元素长度小于 64 字节时使用压缩列表，其他情况使用跳跃表。

*   **压缩列表：**本质是一个字节数组，数组前几个元素存列表长度、尾部偏移量、列表元素个数，数组末尾存列表结束标识。每个元素使用两个紧挨在一起的压缩列表节点来保存，第一个节点保存元素的成员，第二个节点保存元素的分值。
*   **跳跃表：**单向链表按序保存元素及分值，使用哈希表 dict 来保存元素和分值的映射关系。链表增加了多级索引，先从最上层索引跳跃查，再渐渐往下层到链表地查询，实现了快速查找元素，时间复杂度 O(logn)，这种查询算法类似于链表版二分查找，是基于有序的。

**zset 底层不使用红黑树的原因：**

*   **范围查找：**因为红黑树范围查找效率低，而跳跃表范围查找效率高，因为是链表结构。zset 可以用 zrange 命令查指定下标范围内元素，例如 zrange 0 -1。
*   **实现难度：**跳跃表实现比红黑树简单。

压缩列表：

![](<assets/1740030354135.png>)

跳跃表 zrange： 

```
#将a和b两个元素插入到名称为myzset的有序集合中，并为它们分别设置了分值为10和9
zset myzset 10.0 a 9.0 b 
#返回所有元素，并按照它们的分值从小到大排列。结果为b和a。0表示第一个元素，-1表示最后一个元素
zrange myzset 0 -1
```

![](<assets/1740030354228.png>)

**标准回答**

Redis 有序集合和集合一样也是 **string 类型元素的集合**，且**不允许重复**的成员。不同的是**每个元素**都会关联一个 **double 类型的分数。**Redis 正是**通过分数**来为集合中的成员进行从小到大的**排序**。有序集合的成员是唯一的，但**分数 (score) 却可以重复**。集合是通过哈希表实现的，所以添加，删除，查找的复杂度都是 O(1)。集合中最大的成员数为 232 – 1 ( 4294967295 ) ， 每个集合可存储 40 多亿个成员。

zset 底层的**存储结构**包括 ziplist 或 skiplist，在同时满足有序集合保存的**元素数量小于 128 个**和有序集合保存的所有元素的长度小于 64 字节的时候使用 ziplist，其他时候使用 skiplist。

当 **ziplist** 作为 zset 的底层存储结构时候，每个集合**元素**使用**两个紧挨在一起的压缩列表节点**来保存，第一个节点保存元素的**成员**，第二个元素保存元素的**分值**。

当 **skiplist** 作为 zset 的底层存储结构的时候，使用 **skiplist 按序保存元素及分值**，使用 dict 来保存元素和分值的映射关系。

**加分回答**

实际上单独使用 Hashmap 或 skiplist 也可以实现有序集合，Redis 使用两种数据结构组合的原因是如果我们单独使用 Hashmap，虽然能以 O(1) 的时间复杂度查找成员的分值，但是因为 Hashmap 是以无序的方式来保存集合元素，所以每次进行范围操作的时候都要进行排序；而如果单独使用 skiplist，虽然能执行范围操作，但查找操作的复杂度却由 O(1) 变为了 O(logN)。因此 Redis 使用了两种数据结构来共同实现有序集合。

### 5、说说 Redis 的持久化策略

**得分点**

RDB、AOF

**数据备份机制 RDB（默认）：数据**定期写进磁盘 rdb 文件，故障后从文件读。占 CPU 和内存但恢复快，不能恢复完整数据。save 命令是主进程立即执行一次 RDB，其他所有命令进程阻塞。bgsave 是子进程 fork 主进程，阻塞并拷贝一份主进程的页表（虚拟内存到物理内存的映射关系），然后子进程写数据到 rdb 文件，主进程继续处理用户请求，

*   **save <seconds> <changes>：**多少秒内多少 key 修改时自动 bgsave。默认 save 900 1 ，即 900s 内只要有一个 key 被更改就会 bgsave。
*   **rdbcompression ：**是否用 LZF 算法压缩 rdb 文件，默认值是 yes。压缩会占用 CPU，追求效率可关闭，追求空间可开启。

**追加文件机制 AOF：**命令**日志**按持久化策略异步写进磁盘 aof 文件，故障后从文件读命令恢复数据。重写：可以按指定的重写阈值自动执行 bgrewriteaof 命令，异步重写 aof 文件中的命令日志，保证多次更新同一数据只有最近一次更新有效。不占 CPU 和内存占 IO，能恢复完整数据。

*   **appendfsync  ：**持久化策略。
    *   **always：**每次写入后都执行 fsync 命令，异步写 aof 文件，效率高。默认值。
    *   **everysec（推荐）：**写入 1s 后 fsync，虽然会丢失 1s 但效率高。
    *   **no：**不建议，让操作系统决定什么时候 fsync，不安全
*   **auto-aof-rewrite-percentage <percentage>：**比上次重写 aof 文件超过多少百分比时自动重写
*   **auto-aof-rewrite-min-size <bytes>：**aof 文件超过多大自动重写

**RDB-AOF 混合持久化：** Redis 4.0 支持混合持久化，基于 aof 的 bgrewriteaof 命令实现。aof 重写时，fork 出的子进程先将全量数据以 RDB 方式写入新的 AOF 文件，然后再将 AOF 重写缓冲区（aof_rewrite_buf_blocks）的增量命令以 AOF 方式写入到文件，写入完成后通知主进程覆盖旧的 aof 文件。aof 文件前半段保存 RDB 格式的全量数据，后半段保存 AOF 格式的增量数据。可以快速恢复且恢复 1s 之前的数据。

*   aof-use-rdb-preamble yes：开启混合持久化

**标准回答** 

**Redis 4.0 支持混合持久化、支持懒释放（开启后，删除 key 在后台运行，提高效率）**

Redis4.0 之后，Redis 有 RDB 持久化、AOF 持久化、RDB-AOF 混合持久化这三种持久化方式。

**RDB 持久化**是将当前进程数据以生成快照的方式保存到硬盘的过程，也是 Redis 默认的持久化机制。RDB 会创建一个经过压缩的二进制文件，这个文件以’.rdb‘结尾，内部存储了各个数据库的键值对等信息。RDB 持久化过程有手动触发和自动触发两种方式。手动触发是指通过 SAVE 或 BGSAVE 命令触发 RDB 持久化操作，创建 “.rdb” 文件；自动触发是指通过配置选项，让服务器在满足指定条件时自动执行 BGSAVE 命令。RDB 持久化的优点是其生成的紧凑压缩的二进制文件体积小，使用该文件恢复数据的速度非常快；缺点则是 BGSAVE 每次运行都要执行 fork 操作创建子进程，这属于重量级操作，不宜频繁执行，因此，RBD 没法做到实时的持久化。

AOF 全称为 Append Only File（追加文件）。

**AOF** 以独立日志的方式记录了每次写入的命令，重启时再重新执行 AOF 文件中的命令来恢复数据。AOF 持久化的优点是与 RDB 持久化可能丢失大量的数据相比，AOF 持久化的安全性要高很多。通过使用 everysec 选项，用户可以将数据**丢失的时间窗口限制在 1 秒之内**。其缺点则是，AOF 文件存储的是协议文本，它的体积要比二进制格式的”.rdb” 文件大很多。AOF 需要通过执行 AOF 文件中的命令来恢复数据库，其恢复速度比 RDB 慢很多。AOF 在进行**重写时也需要创建子进程**，在数据库体积较大时将占用大量资源，会导致服务器的短暂阻塞。AOF 解决了数据持久化的实时性，是目前 Redis 主流的持久化方式。

**RDB-AOF 混合持久化模式**是 Redis4.0 开始引入的，这种模式是**基于 AOF 持久化**构建而来的。用户可以通过配置文件中的 “aof-use-rdb-preamble yes” 配置项开启 AOF 混合持久化。Redis 服务器在执行 **AOF 重写操作时**，会**像执行 BGSAVE 命令一样**，根据数据库当前的状态**生成相应的 RDB 数据**，并将其写入 **AOF 文件中**；对于重写之后执行的 Redis 命令，则以协议文本的方式追加到 AOF 文件的末尾，即 RDB 数据之后。

通过使用 RDB-AOF 混合持久化，用户可以同时获得 RDB 持久化和 AOF 持久化的优点，服务器既可以通过 AOF 文件包含的 RDB 数据来实现**快速的数据恢复操作**，又可以通过 AOF 文件包含的 AOF 数据来将**丢失数据的时间窗口限制在 1s** 之内

**加分回答 - RDB 的 save 和 bgsave、AOF 的文本协议格式和文件同步机制：**

RDB 手动触发分别对应 save 和 bgsave 命令：

- save 命令会一直阻塞当前 Redis 服务器到 RBD 过程完成为止，所以这种方式在操作内存比较大的实例时会造成长时间阻塞，因此线上环境不建议使用，该命令已经被废弃。

- bgsave 命令会让 Redis 进程执行 fork 创建子进程，由子进程负责 RBD 持久化过程，完成后自动结束，因此只在 fork 阶段发生阻塞，一般阻塞的时间也不会很长。因此 Redis 内部所涉及的几乎所有 RDB 操作都采用了 bgsave 的方式。

除了执行命令手动触发之外，Redis 内部还存在自动触发 RDB 的持久化机制，例如以下场景：

1. 使用 save 相关配置，如 “save m n”。表示 m 秒内数据集存在 n 次修改 时，自动触发 bgsave。

2. 如果从节点执行全量复制操作，主节点自动执行 bgsave 生成 RDB 文件并发送给从节点。

3. 执行 debug reload 命令重新加载 Redis 时，也会自动触发 save 操作。

4. 默认情况下执行 shutdown 命令时，如果没有开启 AOF 持久化功能则 自动执行 bgsave。

AOF 默认不开启，需要修改配置项来启用它：

```
appendonly yes # 启用AOF 
appendfilename “appendonly.aof“ # 设置文件名
```

AOF 以**文本协议格式写入命令**，如： *3\r\n$3\r\nset\r\n$5\r\nhello\r\n$5\r\nworld\r\n

文本协议格式具有如下的优点：

1. 文本协议具有很好的兼容性；

2. 直接采用文本协议格式，可以避免二次处理的开销；

3. 文本协议具有可读性，方便直接修改和处理。

AOF 持久化的**文件同步机制：**

为了提高程序的写入性能，现代操作系统会把针对硬盘的多次写操作优化为一次写操作。

1. 当程序调用 write 对文件写入时，系统不会直接把书记写入硬盘，而是先将数据写入内存的缓冲区中；

2. 当达到特定的时间周期或缓冲区写满时，系统才会执行 flush 操作，将缓冲区中的数据冲洗至硬盘中；

这种优化机制虽然提高了性能，但也给程序的写入操作带来了不确定性。

1. 对于 AOF 这样的持久化功能来说，冲洗机制将直接影响 AOF 持久化的安全性；

2. 为了消除上述机制的不确定性，Redis 向用户提供了 appendfsync 选项，来控制系统冲洗 AOF 的频率；

3. Linux 的 glibc 提供了 fsync 函数，可以将指定文件强制从缓冲区刷到硬盘，上述选项正是基于此函数。

### 6、说说缓存穿透、击穿、雪崩的区别

**得分点**

三种问题的发生原因以及解决方式

**缓存穿透：** 指高并发查询一个缓存库和数据库都不存在的数据，一瞬间所有请求没命中缓存，都到达数据库，导致数据库压力过大，从而崩溃。解决：

*   **缓存空对象：**当一个线程查缓存库没命中、查数据库并缓存空值后，其他线程查缓存库直接就命中了，命中的值是字符串 “null”。
*   **布隆过滤器：**应用启动的时候把存在的数据缓存到布隆过滤器里面。每一次请求进来的时候先访问布隆过滤器，如果不存在，则说明这个数据一定没有在数据库里面，就没必要再去访问数据库了。
    *   **底层：**布隆过滤器是一个基于哈希表的数据结构，底层是二进制数组（只能存 0 或 1）和多个哈希函数，用来判断某个元素是否在集合里。
    *   **过程：**元素通过多个哈希函数计算后得到多个 key，将二进制数组这几个 key 对应 value 设为 1（默认是 0），标记该元素已存在于布隆过滤器。
    *   **适用场景：**数据量非常大并且只判断两种状态（例如存在或不存在）的情况。
    *   **优缺点：**优点是空间时间复杂度都很优秀。缺点是可能因为哈希散列后碰撞导致误判，如果判断不存在则一定不存在，判断存在则是可能存在。
    *   **减少误判率：**增加二进制位数组的长度（数组中数据更加散列化）、增加 Hash 的次数（变相增加数字特征，特征越多越不容易误判）
    *   **删除数据后同步布隆过滤器：**因为存在哈希碰撞，所以直接改 1 为 0 可能导致误删。
        *   **定时任务复制替换：**开发定时任务，每隔几个小时，自动创建一个新的布隆过滤器数组并加载数据库数据，替换老的，有点 CopyOnWriteArrayList 的味道
        *   **计数器数组防止误删：**布隆过滤器增加一个等长的数组，存储计数器，主要解决冲突问题，每次删除时对应的计数器减一，如果结果为 0，更新主数组的二进制值为 0
    *   **实现：**通过 Redisson 可以创建布隆过滤器，初始化时可以设置数组长度和误判率：
        
        ```
        RBloomFilter<String> bloomFilter = redissonClient.getBloomFilter();
                //初始化布隆过滤器：预计元素为100000000L,误差率为3%
                bloomFilter.tryInit(100000000L,0.03);
                //将号码10086插入到布隆过滤器中
                bloomFilter.add("10086");
                //判断下面号码是否在布隆过滤器中
                System.out.println(bloomFilter.contains("123456"));//false
        ```
        

**缓存击穿：**一个热点数据缓存失效的瞬间，大量请求都同时没命中、都同时查数据库缓存实值或空值，导致数据库压力过大。

解决：热点数据不设置过期时间，或者互斥锁（同一时刻只允许一个线程访问缓存库该数据，Redis 查询性能高，即使加锁情况下也远远优于数据库）。

**缓存雪崩：**大量数据同时过期，高并发查缓存库和数据库导致崩溃。解决办法：

1.  过期时间附加随机数
2.  **熔断降级：**熔断（服务异常后，阻止上游服务调用该服务）和降级（上游服务远程调用发现下游熔断后，执行后备方法）
3.  **缓存预热：**不要等到请求到来再去查询数据库存入缓存，可以提前将数据存入缓存。使用缓存预热机制通常有专门的后台程序（例如定时任务）去将数据库的数据同步到缓存。

**标准回答**

**缓存穿透：**是指客户端查询了根本不存在的数据，使得这个请求直达存储层，导致其负载过大甚至造成宕机。这种情况可能是由于业务层误将缓存和库中的数据删除造成的，当然也不排除有人恶意攻击，专门访问库中不存在的数据导致缓存穿透。

我们可以通过缓存空对象的方式和布隆过滤器两种方式来解决这一问题。缓存空对象是指当存储层未命中后，仍然将**空值存入缓存层** ，当客户端再次访问数据时，缓存层直接返回空值。

还可以将数据存入**布隆过滤器**。当一个请求到来时，先对其进行布隆过滤器的查询，如果查询结果为不存在，则该请求直接返回空结果。 当布隆过滤器判断元素存在时，此时需要进行进一步的验证，即访问数据库或缓存，获取具体值并返回，同时将该值加入缓存中。

```
public class RedissonBloomFilter {
 
    public static void main(String[] args) {
        Config config = new Config();
        config.useSingleServer().setAddress("redis://192.168.14.104:6379");
        config.useSingleServer().setPassword("123");
        //构造Redisson
        RedissonClient redisson = Redisson.create(config);
 
        RBloomFilter<String> bloomFilter = redisson.getBloomFilter("phoneList");
        //初始化布隆过滤器：预计元素为100000000L,误差率为3%
        bloomFilter.tryInit(100000000L,0.03);
        //将号码10086插入到布隆过滤器中
        bloomFilter.add("10086");
 
        //判断下面号码是否在布隆过滤器中
        System.out.println(bloomFilter.contains("123456"));//false
        System.out.println(bloomFilter.contains("10086"));//true
    }
}
```

**缓存击穿：**当**一份**访问量非常大的**热点数据缓存失效的瞬间**，大量的请求直达存储层，导致服务崩溃。

缓存击穿可以通过**热点数据不设置过期时间**来解决，这样就不会出现上述的问题，这是 “物理” 上的永不过期。或者为每个数据设置**逻辑过期时间**，当发现该数据逻辑过期时，使用单独的线程重建缓存。除了永不过期的方式，我们也可以通过加**互斥锁**的方式来解决缓存击穿，即对数据的访问加互斥锁，**当一个线程访问该数据时，其他线程只能等待**。这个线程访问过后，缓存中的数据将被重建，届时其他线程就可以直接从缓存中取值。

**缓存雪崩：**是指当某一时刻缓存层无法继续提供服务，导致所有的请求直达存储层，造成数据库宕机。可能是缓存中有**大量数据同时过期**，也可能是 Redis 节点发生故障，导致大量请求无法得到处理。

缓存雪崩的解决方式有三种；第一种是在设置**过期时间**时，**附加一个随机数**，避免大量的 key 同时过期。第二种是启用**降级和熔断**措施，即发生雪崩时，若应用访问的不是核心数据，则直接返回预定义信息 / 空值 / 错误信息。或者在发生雪崩时，对于访问缓存接口的请求，客户端并不会把请求发给 Redis，而是直接返回。第三种是**构建高可用的 Redis 服务**，也就是采用**哨兵或集群模式**，部署多个 Redis 实例，这样即使个别节点宕机，依然可以保持服务的整体可用。

### 7、如何利用 Redis 实现一个分布式锁？

**得分点**

为什么要实现分布式锁、实现分布式锁的方式、Redlock

**分布式锁的主要作用：**

1.  **保证数据的正确性：**比如秒杀的时候防止商品超卖，表单重复提交，接口幂等性。
2.  **避免重复执行任务：**在分布式任务调度中，多个节点可能同时执行同一个任务，使用分布式锁可以确保同一时刻只有一个节点能够执行该任务，以避免重复执行的问题。

**设计分布式锁的主要考虑因素：**

1.  **互斥：**同一时刻只能有一个线程获得锁。
2.  **可重入：**当一个线程获取锁后，在解锁之前可以再次获取这个锁，无需等待，只需记录重入次数。可重入锁能避免死锁发生，因为不用线程自己等待自己释放锁。不可重入锁：JDK8 的乐观读写锁 StampedLock，性能比 ReadWriteLock 快但不可重入。
3.  高可用：当小部分节点挂掉后，仍然能够对外提供服务。
4.  **高性能：**要做到高并发、低延迟。
5.  **防死锁：** 如果一个线程对同一把锁, 连续加了两次锁, 并且该锁还是不可重入锁的时候, 就会产生死锁。
6.  支持阻塞和非阻塞：Synchronized 是阻塞的，ReentrantLock.tryLock() 就是非阻塞的
7.  支持公平锁和非公平锁：Synchronized 是非公平锁，ReentrantLock(boolean fair) 可以创建公平锁

**分布式锁的实现方式：**

*   **MySQL 乐观锁；**
*   **基于 Redis：**例如 setnx、Redisson。
*   **基于 zookeeper：**多线程向 zookeeper 创建一个子目录 (节点) 只会有一个创建成功，利用此特点可以实现分布式锁，谁创建该结点成功谁就获得锁。

**setnx 实现分布式锁：** 

**加锁：**setnx，原子性判断 key 不存在、加锁、设置过期时间，value 设为随机 uuid。

*   **原子性判断和加锁：**防止还没来得及加锁，多个线程同时通过判断语句，导致先后加锁。而其实一个线程加锁解锁成功后，其他线程理应过不了判断的。
*   **设置过期时间：**防止死锁。防止拿到锁的线程还**没来得及释放锁**，就因为宕机、异常等因素导致锁无法释放。加过期时间能保证死锁能在指定时长后自动过期。
*   **原子性设置过期时间：**防止死锁。如果不是原子性，刚加完锁，**没来得及设置过期时间**就故障，导致死锁。注意过期时间要设置久一点，保证业务执行完之后再过期。
*   **value 设置随机值：**保证解能判断锁时到当前锁是不是本线程持有的锁。防止解锁前本线程锁已过期，然后其他线程已拿到锁，这时原子性判断解锁时发现加锁，就解锁，而其实解的是其他线程的锁。

```
lock(); // 加锁
try{
    // do something
}finally{
    unlock(); // 解锁
}
 
//不推荐
try{
int a=3/0;//这里抛异常会直接进入finally
lock(); // 加锁
    // do something
}finally{
    unlock(); // 解锁
}
```

**解锁：**lua 脚本原子性判断和解锁，根据比较 value 和自己加锁时设置的随机 id 判断是否自己的锁。原子性判断和解锁：防止刚判断完自己锁过期了，没来得及解锁锁过期其他线程拿到锁。

**业务流程：**先加锁，如果加锁成功就查数据库数据、解锁、返回数据；如果加锁失败就重新调用本方法，再次加锁解锁，直到成功拿到数据库的数据。

**故障转移导致 setnx 在非单机模式下失效：**因为 redis 在进行主从复制时是异步完成的，比如在 clientA 获取锁后，主 redis 复制数据到从 redis 过程中崩溃了，导致没有复制到从 redis 中，然后从 redis 选举出一个升级为主 redis, 造成新的主 redis 没有 clientA 设置的锁，这是 clientB 尝试获取锁，并且能够成功获取锁，导致互斥失效。集群模式在 key 取余后存的实际还是主从，所以也有这个问题。

**Redisson 实现分布式锁：** 

Redisson 基于 Redis 协议，可以实现可重入锁、公平锁、读写锁、信号量、闭锁（计数器），支持看门狗自动续期。

**使用步骤：**

1.  导入依赖
2.  配置类注册 Redisson 客户端
3.  注入客户端通过 getLock(),getReadWriteLock() 等方法获取锁。Redisson 的读写锁实现了 JUC.locks.ReadWriteLock 接口，读读不互斥，读写互斥，写写互斥
4.  加锁：如果没指定过期时间，默认过期时间 30s，剩 10s 时（过期时间的 1/3）看门狗自动续期到 30s。如果指定了过期时间，则不自动续期。建议指定一个充裕的过期时间，既保证过期前能执行完业务，又防止自动续期导致死锁。
5.  解锁。

**try 和 lock 顺序：**加锁代码要放到 try 外面。如果放在 try 里面的话，加锁失败抛异常或者加锁前的代码抛异常后，执行 finally 里的解锁代码，而其实加锁都没成功，最终解锁就也不合适了。

```
# 加锁 
set key random-value nx ex seconds 
# 解锁 
if redis.call(“get“，KEYS【1】) == ARGV【1】 then return redis.call(“del“，KEYS【1】) else return 0 end
```

**wait 指令：**

Redisson 内部曾经实现了 Redlock，解决主从模式下互斥锁失效的问题，后面被弃用，使用 wait 指令（将主从复制过程由异步改为同步）保证锁的一致性。wait 指令是 **Redis3.0** 版本以后才出现的。

**3.12.5 版本弃用的 Redlock：**

Redisson 内部曾经实现了 Redlock，解决主从模式下互斥锁失效的问题。

master 刚加完锁还没来得及主从复制就超时或故障，没有锁信息的 salve 被选为新 master，于是另一个线程此时就能加锁成功，此时就有两个线程拿到了锁，互斥锁的互斥特性失效。

**Redlock 原理：**

redlock 是把所有节点当做是独立的节点，不存在主从复制、集群（集群在 key 散列后其实也是主从模式），每个节点都存一个锁。首先获取当前毫秒为单位的时间戳。然后从所有节点使用相同的 key 和随机值获取锁，客户端会用当前时间减去开始获取锁时间就得到获取各节点锁时长。**只有当大多数的 Redis 节点都取到锁，并且锁获取时长小于锁失效时间（即正常获取到锁）时，锁才算获取成功，否则就是加锁失败，解锁全部节点。** 

**Redlock 详细过程：**对集群的每个节点进行加锁，如果大多数（N/2+1）加锁成功了，则认为获取锁成功。

1.  获取当前时间戳
    
2.  client 尝试按照顺序使用相同的 key,value 获取所有 redis 服务的锁，在获取锁的过程中的获取时间比锁过期时间短很多，这是为了不要过长时间等待已经关闭的 redis 服务。并且试着获取下一个 redis 实例。比如：TTL 为 5s, 设置获取锁最多用 1s，所以如果一秒内无法获取锁，就放弃获取这个锁，从而尝试获取下个锁
    
3.  client 通过获取所有能获取的锁后的时间减去第一步的时间，这个时间差要小于 TTL 时间并且至少有 3 个 redis 实例成功获取锁，才算真正的获取锁成功
    
4.  如果成功获取锁，则锁的真正有效时间是 TTL 减去第三步的时间差 的时间；比如：TTL 是 5s, 获取所有锁用了 2s, 则真正锁有效时间为 3s(其实应该再减去时钟漂移);
    
5.  如果客户端由于某些原因获取锁失败，便会开始解锁所有 redis 实例；因为可能已经获取了小于 3 个锁，必须释放，否则影响其他 client 获取锁
    

Redisson RedLock 是基于联锁 MultiLock 实现的，但是使用过程中需要自己判断 key 落在哪个节点上，对使用者不是很友好。

**Redisson RedLock 已经被弃用，直接使用普通的加锁即可**，会**基于 wait 机制**将锁同步到从节点，但是也并不能保证一致性。仅仅是最大限度的保证一致性。

**wait 指令：**

Redis 的复制是异步进行的，wait 指令可以让异步复制变身同步复制，确保系统的强一致性 (不严格)。wait 指令是 Redis3.0 版本以后才出现的。

**标准回答**

在分布式的环境下，会发生多个 server 并发修改同一个资源的情况，这种情况下，由于多个 server 是多个不同的 JRE 环境，而 Java 自带的锁局限于当前 JRE，所以 Java 自带的锁机制在这个场景下是无效的，那么就需要我们自己来实现一个分布式锁。

采用 Redis 实现分布式锁，我们可以在 Redis 中存一份代表锁的数据，数据格式通常使用字符串即可。

首先加锁的逻辑可以通过 **`setnx key value`** 来实现，但如果客户端忘记解锁，那么这种情况就很有可能造成死锁，但如果直接给锁**增加过期时间**即新增 `expire key seconds` 又会发生其他问题，即这两个命令并不是原子性的，那么如果第二步失败，依然无法避免死锁问题。考虑到如上问题，我们最终可以通过 `set...nx...` 命令，将**加锁、过期命令编排到一起**，把他们变成**原子操作**，这样就可以避免死锁。写法为 `set key value nx ex seconds` 。

解锁就是将代表锁的那份数据删除，但不能用简单的 `del key`，因为会出现一些问题。比如此时有进程 A，如果进程 A 在任务没有执行完毕时，锁被到期释放了。这种情况下进程 A 在任务完成后依然会尝试释放锁，因为它的代码逻辑规定它在任务结束后释放锁，但是它的锁早已经被释放过了，那这种情况它释放的就可能是其他线程的锁。为解决这种情况，我们可以在**加锁时为 key 赋一个随机值，来充当进程的标识**，进程要记住这个标识。当进程解锁的时候进行判断，**是自己持有的锁才能释放**，否则不能释放。另外判断，释放这两步需要保持**原子性**，否则如果第二步失败，就会造成死锁。而获取和删除命令不是原子的，这就需要采用 **Lua 脚本**，通过 Lua 脚本将两个命令编排在一起，而整个 Lua 脚本的执行是原子的。综上所述，优化后的实现分布式锁命令如下：

```
//分布式锁
    public Object fun() {
        // 1、分布式锁。去redis占坑，同时设置过期时间
 
        //每个线程设置随机的UUID，也可以成为token
        String uuid = UUID.randomUUID().toString();
 
        //只有键key不存在的时候才会设置key的值。保证分布式情况下一个锁能进线程
        Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", uuid, 300, TimeUnit.SECONDS);
        if (lock) {
            // 加锁成功....执行业务【内部会判断一次redis是否有值】
            System.out.println("获取分布式锁成功....");
            Object ans= null;
            try {
                ans= getDataFromDb();
            } finally {
                // 2、查询UUID是否是自己，是自己的lock就删除
                // 查询+删除 必须是原子操作：lua脚本解锁
                String luaScript = "if redis.call('get',KEYS[1]) == ARGV[1]\n" +
                        "then\n" +
                        "    return redis.call('del',KEYS[1])\n" +
                        "else\n" +
                        "    return 0\n" +
                        "end";
                // 删除锁
                Long lock1 = redisTemplate.execute(
                        new DefaultRedisScript<Long>(luaScript, Long.class),
                        Arrays.asList("lock"), uuid);    //把key和value传给lua脚本
            }
            return ans;
        } else {
            System.out.println("获取分布式锁失败....等待重试...");
            // 加锁失败....重试
            // 休眠100ms重试
            try {
                Thread.sleep(200);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return fun();// 自旋的方式
        }
    }
```

```
//分布式锁
    public Object fun() {
        // 1、分布式锁。去redis占坑，同时设置过期时间
 
        //每个线程设置随机的UUID，也可以成为token
        String uuid = UUID.randomUUID().toString();
 
        //只有键key不存在的时候才会设置key的值。保证分布式情况下一个锁能进线程
        Boolean lock = redisTemplate.opsForValue().setIfAbsent("lock", uuid, 300, TimeUnit.SECONDS);
        if (lock) {
            // 加锁成功....执行业务【内部会判断一次redis是否有值】
            System.out.println("获取分布式锁成功....");
            Object ans= null;
            try {
                ans= getDataFromDb();
            } finally {
                // 2、查询UUID是否是自己，是自己的lock就删除
                // 查询+删除 必须是原子操作：lua脚本解锁
                String luaScript = "if redis.call('get',KEYS[1]) == ARGV[1]\n" +
                        "then\n" +
                        "    return redis.call('del',KEYS[1])\n" +
                        "else\n" +
                        "    return 0\n" +
                        "end";
                // 删除锁
                Long lock1 = redisTemplate.execute(
                        new DefaultRedisScript<Long>(luaScript, Long.class),
                        Arrays.asList("lock"), uuid);    //把key和value传给lua脚本
            }
            return ans;
        } else {
            System.out.println("获取分布式锁失败....等待重试...");
            // 加锁失败....重试
            // 休眠100ms重试
            try {
                Thread.sleep(200);
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
            return fun();// 自旋的方式
        }
    }
```

**加分回答**

上述的分布式锁实现方式是建立在**单节点**之上的，它可能存在一些问题，比如有一种情况，进程 A 在主节点加锁成功，但主节点宕机了，那么从节点就会晋升为主节点。那如果此时另一个进程 B 在新的主节点上加锁成功而原主节点重启了，成为了从节点，系统中就会出现两把锁，这违背了锁的唯一性原则。

总之，就是在单个主节点的架构上实现分布式锁，是无法保证高可用的。若要保证**分布式锁的高可用**，则可以采用多个节点的实现方案。这种方案有很多，而 Redis 的官方给出的建议是采用 RedLock 算法的实现方案。该算法基于多个 Redis 节点，它的基本逻辑如下：

- 这些节点相互独立，不存在主从复制或者集群协调机制；

- 加锁：以相同的 KEY 向 N 个实例加锁，只要超过一半节点成功，则认定加锁成功；

- 解锁：向所有的实例发送 DEL 命令，进行解锁；

我们可以自己实现该算法，也可以直接使用 **Redisson** 框架。

### 8、Redis 如何与数据库保持双写一致性

**得分点**

四种同步策略及其可能出现的问题，几种删除方案

**四种同步策略：**

*   先更新缓存再更新数据库：第二步失败缓存库是脏数据
*   **先更新数据库再更新缓存：**第二步失败缓存库是旧数据
*   先删除缓存再更新数据库：第二步失败缓存库是空数据
*   **先更新数据库、再删除缓存（推荐）：**第二步失败缓存库是旧数据

**同步删除方案：** 适用于不强制要求数据一致性的情景

*   **流程：**先更新数据库、再删除缓存。
*   **问题：**
    *   并发时脏数据：在查询数据库到写缓存期间其他线程执行了一次更新删除，导致缓存的数据是旧数据
    *   缓存删除失败：删除失败导致缓存库还是旧数据

**同步删除 + 可靠消息：** 适用于不强制要求数据一致性的情景

*   **流程：**先更新数据库、再删除缓存，如果删除失败就发可靠 MQ 不断重试删除缓存，直到删除成功或重试 5 次。
*   **问题：**MQ 多次重试失败，导致长期脏数据。

**延时双删方案：**

*   **流程：**先删除缓存再更新数据库，大约在数据库从库更新后再删一次。
*   **问题：**时间无法控制，不能保证在数据库从库更新后删除缓存。如果在从库更新前删除，用户再在更新前查从库又把脏数据写在缓存里了。

**异步监听 + 可靠消息删除（主流）：**

*   **流程：**
    *   更新数据库后不做操作；
    *   Canal 等组件监听 binlog 发现有更新时就发可靠 MQ 删除缓存；
*   **问题：**binlog 抓取组件故障，导致长期脏数据。

**多重保障方案：**同步删除 + 异步监听 + 可靠消息删除，缓存时设置过期时间，查询时强制主库查；适合于强制要求数据一致性的情况

1.  **同步删除：**先更新数据库、再删除缓存；之后本链路禁止再查该数据，防止没来得及删缓存就又查到旧缓存数据。
2.  **Canal 监听：**Canal 等组件监听 binlog 发现有更新时就发可靠 MQ 删除缓存；第二重保证删缓存成功；
3.  **延迟消息校验一致性：**Canal 等组件监听 binlog，发延迟 MQ，N 秒后校验缓存一致性；
4.  **缓存过期时间：**每次缓存时设置过期时间；第三重保证删缓存成功；
5.  **强制 Redis 主库查：**以后查缓存时强制从缓存主库查；因为主从同步有延迟，同时不用担心主库压力大，因为分片集群机制。

**标准回答**

保证缓存和数据库的双写一致性，共有**四种同步策略**，即先更新缓存再更新数据库、先更新数据库再更新缓存、先删除缓存再更新数据库、先更新数据库再删除缓存。

**更新缓存**的优点是每次数据变化时都能**及时地更新缓存**，这样不容易出现查询未命中的情况，但这种操作的**消耗很大**，如果数据需要经过复杂的计算再写入缓存的话，频繁的更新缓存会影响到服务器的性能。如果是写入数据比较频繁的场景，可能会导致频繁的更新缓存却没有业务来读取该数据。

**删除缓存**的优点是操作简单，无论更新的操作复杂与否，都是直接删除缓存中的数据。这种做法的缺点则是，当删除了缓存之后，下一次容易出现未命中的情况，那么这时就需要再次读取数据库。查询

那么对比而言，**删除缓存无疑是更好的选择**。

那么我们再来看一下先操作数据库和后操作数据库的区别:

**先删除缓存再操作数据库**的话，如果第二步骤失败可能导致缓存和数据库得到相同的**旧数据**。先操作数据库但删除缓存失败的话则会导致缓存和数据库得到的结果不一致。

出现上述问题的时候，我们一般采用**重试机制解决**，而为了避免重试机制影响主要业务的执行，一般建议重试机制采用**异步**的方式执行。当我们采用重试机制之后由于存在并发，先删除缓存依然可能存在缓存中存储了旧的数据，而数据库中存储了新的数据，二者数据不一致的情况。

所以我们得到结论：**先更新数据库、再删除缓存是影响更小的方案**。如果第二步出现失败的情况，则可以采用重试机制解决问题。

### 9、说说 Redis 的主从同步机制

**得分点**

psync，全量复制、部分复制

**主从同步：**从节点可以连接主节点同步数据。同步过程中，主从节点通过心跳、断开重连等机制确保同步的高可靠性和稳定性。

主从节点实现了数据备份和读写分离。

**全量同步：**

1.  slave 节点请求增量同步
2.  master 节点对比主从库的 replid，发现不一致，拒绝增量同步
3.  master 执行 bgsave 子进程生成 RDB 文件，然后发给 slave
4.  slave 清空本地数据，接收 RDB 文件写入磁盘，再载入内存；
5.  master 将 RDB 期间的命令记录在 repl_backlog，并持续将 log 中的命令发送给 slave
6.  slave 执行接收到的命令，增量同步，保持与 master 之间的同步

**replid：**复制 ID，全称 Replication Id。每一个 master 都有唯一的 replid，全量复制后 slave 继承 master 的复制 ID。以后同步两者 replid 相同，是同一数据集，做增量同步。

**bgsave：**子进程 fork 主进程，阻塞并拷贝一份主进程的页表（虚拟内存到物理内存的映射关系），然后子进程写数据到 rdb 文件，主进程继续处理用户请求。

**repl_backlog：**即 Replication Backlog，译为复制积压日志，用来记录全量同步后的所有写命令。底层是一个循环链表，每个库用一个 offset（偏移量）指针，指向这个库最新命令的节点。哨兵模式选主时是优先看节点配置的优先值、优先值一样时比较 repl_backlog 里 offset 选数据最新的节点、offset 一致再选用 id 小的节点作为新 master。

**增量同步：**

1.  slave 节点请求增量同步
2.  master 节点对比主从库的 replid，发现一致，同意增量同步；
3.  master 对比主从库 offset，只更两者存在差异的部分数据，然后调整两者的 offset 位置。 

**详细参考：**[SpringCloud 基础 7——Redis 分布式缓存，RDB,AOF 持久化 + 主从 + 哨兵 + 分片集群_springcloud 整合 redis 缓存_vincewm 的博客 - CSDN 博客](https://blog.csdn.net/qq_40991313/article/details/126912298?spm=1001.2014.3001.5501 "SpringCloud基础7——Redis分布式缓存，RDB,AOF持久化+主从+哨兵+分片集群_springcloud整合redis缓存_vincewm的博客-CSDN博客") 

**标准回答**

Redis 主从同步是指**任意数量的从节点**（slave node）都可以从**主节点**上（master node）**同步数据**。而除了多个 slave 可以连接到同一个 master 之外，**slave 还可以接受其他 slave 的连接**，这就形成一个树形结构，使得 Redis 可执行单层树复制。

在同步过程中，主节点和从节点还会保持**心跳、断开重连**等机制，以确保同步的高可靠性和稳定性。Redis 主从同步机制可以实现**数据的备份和读写分离**，提高 Redis 系统的可用性和性能。 

从 2.8 版本开始，当启动一个 slave node 的时候，它会发送一个 `PSYNC` 命令给 master node，PSYNC 译为部分同步。

如果 slave node 是第一次连接到 master node，那么会触发一次**全量复制**。此时 **master** 会启动一个后台线程，开始**生成一份 `RDB` 快照文件**，同时还会将从客户端 client 新收到的所有**写命令缓存在内存中**。

`RDB` 文件生成完毕后， master 会将这个 `RDB` 发送给 slave，slave 会先写入本地磁盘，然后再从本地磁盘加载到内存中，接着 master 会将内存中**缓存的写命令发送到 slave**，slave 也会同步这些数据。

slave node 如果跟 master node 有网络故障，断开了连接，会**自动重连**，连接之后 master node 仅会复制给 slave 部分缺少的数据，即**部分复制**。

### 10、如何实现 Redis 高可用（主从哨兵集群）

**得分点**

主从模式、哨兵模式、集群模式

**三种高可用方案：** 主从、哨兵或集群。

主从模式的缺点是无法自动故障转移，master 故障后需要人工介入切换主节点。主从和哨兵缺点是写操作无法负载均衡、存储能力受到单机的限制（只能主库写）。分片集群解决了海量数据存储问题和高并发写的问题。

**哨兵（sentinel）：**哨兵节点是不存储数据的 Redis 节点，多个哨兵节点组成哨兵系统。哨兵的作用如下：

*   **监控：**Sentinel 基于心跳机制每隔 1 秒向集群的每个实例发送 ping 命令，监控实例状态；如果一个实例被单个哨兵 ping 不通，被认为主观下线；如果一个实例被大多数哨兵 ping 不通，被认为客观下线；
*   **自动故障恢复：**如果 master 客观下线，Sentinel 会优先根据 slave-priority 值（越小优先级越高）、offset 值（越大说明数据越新）、id 值（前面数值相同时 id 越小优先级越高）选一个 slave 提升为 master，将旧 master 标记为 slave。当故障实例恢复后也以新的 master 为主
*   **通知：**当集群发生故障转移时，Sentinel 会将最新信息推送给 Redis 的客户端。
*   **缺点：**写操作无法负载均衡，只能一个 master 写数据，存储能力受到单机的限制。脑裂。
*   **脑裂：**选主后旧主恢复，导致两个 master 同时工作。**解决方案：**master 配置两个参数，使旧 master 恢复后无法写数据。例如要求 master 从库数量最少 3 个，且主从同步的时长不能超过 10s。不满足就拒绝 mater 写入数据。
    *   min-slaves-to-write 3：master 的最少 slave 数量。默认是 0。
    *   min-slaves-max-lag 10：主从同步的最大延迟时长。默认是 10。
*   **版本**：Redis2.8 开始引入。

**分片集群：**

*   **多个主节点**：集群中有多个 master，每个 master 通过映射的插槽保存对应的数据。每个 master 都可以有多个 slave 节点
    
*   **散列插槽：**Redis 会把所有 master 映射到 0~16383 共 16384 个插槽（即 2^14-1）上，每个 master 负责一部分插槽。读写时，key 做哈希运算并取余后确定插槽位置，该位置负责的 master 实现读写。
    
*   **故障恢复：**master 之间通过 ping/pong 消息（消息内容是心跳包）监测彼此健康状态；如果有 master 故障，哨兵集群会选 salve 升级为 master。**ping/pong 消息：**
    
    *   每秒随机选取 5 个节点，找出最久没有通信的节点发送 ping 消息，如果目标节点畅通则会回发 pong 消息；
        
    *   每 100 毫秒都会扫描本地节点列表，如果发现节点最近一次接受 pong 消息的时间大于 cluster-node-timeout/2 则立刻发送 ping 消息；
        
*   **请求转发**：客户端请求可以访问集群任意节点，最终都会被转发到正确节点。
    
*   **版本**：Redis3.0 开始引入。
    

**标准回答**

主要有哨兵和集群两种方式可以实现 Redis 高可用。

**哨兵：** 哨兵模式是 Redis 的高可用的解决方案，它由一个或多个 Sentinel 实例组成 **Sentinel 系统**，可以**监视**任意多个主服务器以及这些主服务器属下的所有从服务器。当哨兵节点发现**有节点不可达时**，会对该节点做**下线标识**。如果是主节点下线，它还会和其他 Sentinel 节点进行 “协商”，当大多数 Sentinel 节点都认为**主节点不可达**时，它们会**选举**出一个 **Sentinel 节点**来完成**自动故障转移**的工作，同时会将这个变化实时通知给 Redis 应用方。

哨兵节点包含如下的特征：

 1. 哨兵节点会**定期监控数据节点**，其他哨兵节点是否可达；

 2. 哨兵节点会将**故障转移**的结果通知给应用方；

 3. **哨兵节点**可以将从节点**晋升**为主节点，并维护后续正确的主从关系；

 4. 哨兵模式下，客户端连接的是哨兵节点集合，从中获取主节点信息；

 5. 节点的故障判断是由多个哨兵节点共同完成的，可有效地防止误判；

 6. **哨兵节点集合**是由多个哨兵节点组成的，即使个别哨兵节点不可用，整个集合依然是健壮的；

 7. **哨兵节点也是独立的 Redis 节点**，是特殊的 Redis 节点，它们**不存储数据，只支持部分命令**。

**集群：** Redis 集群采用**虚拟槽分区**来实现**数据分片**，它把所有的键根据 CRC16 算法和哈希取余映射到 `0-16383` 整数槽内，计算公式为 `slot=CRC16(key)%16383`，每一个 master 负责维护一部分槽以及槽所映射的键值数据。虚拟槽分区具有如下特点：

1. 解耦数据和节点之间的关系，简化了节点扩容和收缩的难度；

2. 节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据；

3. 支持节点、槽、键之间的映射查询，用于数据路由，在线伸缩等场景。

### 11、为什么 Redis 集群中，哈希槽数量是 16384？

这个问题 Redis 作者有解答过，主要原因：

1.  **心跳包大小正好合适**：集群节点每秒会发心跳包，16384 正好 2kb，不会造成网络拥堵。
2.  **实际场景节点数不会大于 1000**：节点数大于 1000 后会造成网络拥堵，每秒选 5 个节点给最久没通信的节点发心跳包、每 100 毫秒都会扫描本地节点列表最久时间没通信的节点发心跳包，这样就网络拥堵了。1000 差不多就到接受的阈值，此时 16384 正好让每个节点负责十几个插槽，不多不少。

**Redis 作者解答出处：**

[why redis-cluster use 16384 slots?](https://github.com/redis/redis/issues/2576 "why redis-cluster use 16384 slots?")

The reason is:

1.  Normal heartbeat packets carry the full configuration of a node, that can be replaced in an idempotent way with the old in order to update an old config. This means they contain the slots configuration for a node, in raw form, that uses 2k of space with16k slots, but would use a prohibitive 8k of space using 65k slots.
2.  At the same time it is unlikely that Redis Cluster would scale to more than 1000 mater nodes because of other design tradeoffs.

So 16k was in the right range to ensure enough slots per master with a max of 1000 maters, but a small enough number to propagate the slot configuration as a raw bitmap easily. Note that in small clusters the bitmap would be hard to compress because when N is small the bitmap would have slots/N bits set that is a large percentage of bits set.

**翻译过来是：**

*   Redis 节点间通信时，每秒都会 ping/pong 心跳包，心跳包会携带节点的所有槽信息，它能幂等性的更新配置。如果采用 16384 个插槽，占空间 **2KB** (16384/8); 如果采用 65536 个插槽，占空间 8KB (65536/8)。8KB 在网络传输时就有些慢了，会造成网络拥堵。
*   集群不太可能扩展到超过 1000 个主节点，太多可能导致网络拥堵。
*   因此，16384 个插槽范围比较合适。即使当集群扩展到 1000 个节点时，也能确保每个 master 节点有十多个插槽。

### 12、什么是一致性哈希算法？Redis 为什么使用哈希槽而非一致性哈希算法？

**设计目标**：传统哈希表，有主节点挂掉后，哈希取余的分母变化导致分布式缓存系统中，数据存储混乱。使用一致性哈希算法可以保证当集群中节点增加或减少时，只有该节点旁边的一小部分槽需要重新分配存储位置，不会影响整个集群的数据一致性。

**取余**：普通的 hash 算法是对节点数进行 hash，而一致性 hash 是对固定值 2^32 进行取模。

**步骤**：

1.  **构建一致性哈希环**：将节点全部放到一个虚拟的圆环上，其节点范围在 0-2^32-1，首尾相连；
2.  **服务器 IP 节点映射**：将集群中各个节点的 IP，根据哈希算法 hash(IP) 计算哈希值，映射到环上。
3.  **确定元素存在哪个节点**：计算 key 的哈希值，确定在环上位置，然后顺时针行走到的第一个节点是它要存储的节点。至于具体存储在节点机器的哪个位置，则由具体使用哈希一致性算法思想的技术决定。

**优点：**

*   **节点增减时影响小**：集群中节点加入和删除只影响顺时针相邻插槽对应的部分数据，对其他节点存储的数据无影响。如果有节点宕机，不至于所有压力都打到后端服务器上。

**缺点：**

*    **数据倾斜问题**：服务节点少且分布不均匀时，会导致大量节点都存在一台机器上。

**解决方案：**使用虚拟节点，或者改用哈希槽算法（Redis 用的就是哈希槽分区算法）。

*   **虚拟节点**：哈希环上不存真实节点，而是存均匀的虚拟节点，然后每多个虚拟节点映射到一个真实节点。比如 Nginx 的一致性哈希算法，每个权重为 1 的真实节点就含有 160 个虚拟节点。
*   **哈希槽算法：** 
    
    *   **哈希槽算法：**将整个键空间划分为固定大小的多个槽位，每个节点负责一部分槽位的存储。Redis 集群将整个键空间分为 16384 个槽位，每个槽位可以由一个集群节点来管理。
    *   **哈希计算**：当要将一个键值对存储到集群中时，Redis 通过 CRC16 哈希算法计算键的哈希值，然后将其对 16384 取模，得到一个槽位编号（范围在 0 到 16383）。
    *   **槽位分配**：Redis 集群中的节点会分配一定数量的槽位，每个槽位由某个节点负责存储。节点的增加或减少时，Redis 会自动进行槽位迁移，确保数据的均匀分布。

**哈希环存储步骤**：例如存储 Object A 和 Object B 两个 key 到环中：

![](<assets/1740030354322.png>)

**数据倾斜问题**：例如下面括号内所有插槽都要映射到 A 节点：

![](<assets/1740030354650.png>)

### 13、Redis 为什么使用哈希槽而不用一致性哈希？

**哈希槽算法：** 

*   **哈希槽算法：**将整个键空间划分为固定大小的多个槽位，每个节点负责一部分槽位的存储。Redis 集群将整个键空间分为 16384 个槽位，每个槽位可以由一个集群节点来管理。
*   **哈希计算**：当要将一个键值对存储到集群中时，Redis 通过 CRC16 哈希算法计算键的哈希值，然后将其对 16384 取模，得到一个槽位编号（范围在 0 到 16383）。
*   **槽位分配**：Redis 集群中的节点会分配一定数量的槽位，每个槽位由某个节点负责存储。节点的增加或减少时，Redis 会自动进行槽位迁移，确保数据的均匀分布。

**使用哈希槽的优势：**

1.  **简化实现**：相比一致性哈希，哈希槽机制实现简单，不需要虚拟节点来平衡数据。
2.  **高性能**：槽位机制使得 Redis 集群能够快速定位键所在的节点，大大提高了数据访问速度。
3.  **负载均衡**：通过将数据分配到多个槽位，集群在节点扩展或缩减时可以将槽位迁移至其他节点，实现负载均衡。而哈希一致性算法节点就不均匀，导致数据倾斜。
4.  **高可用性**：Redis 集群中槽位与节点的关系允许进行主从复制，在主节点宕机时，会故障转移，备用节点会接管相应的槽位，确保数据的高可用性。

### 14、说说 Redis 的缓存淘汰策略

**得分点**

惰性删除、定期删除，maxmemory-policy

**缓存淘汰策略包括：** 过期策略、内存淘汰策略

**过期淘汰策略：** Redis 可以在 redis.conf 配置以下几种过期策略

*   **定时删除策略：**在设置 key 的过期时间时设置定时器, 当 key 过期时通过定时器删除 key。优点是及时删除，缺点是定时器占用 CPU。
*   **惰性删除策略（默认）：**访问时检查过期，若过期则删除。优点是不耗费 CPU，缺点是不访问不删除导致内存空间的无效占用。Redis 默认策略是惰性 + 定期删除策略。
*   **定期删除策略（默认）：** 贪心算法把已过期 key 比例大致控制在 25% 以内。将指定了过期时间的 key 放在一个字典里，每 10 秒扫描一次，取随机 20 个 key，删除过期 key，若过期比例超过 25%，则重复扫描。折中方案。

**超出指定最大内存淘汰策略**：通过  maxmemory-policy 参数，配置 Redis 超过指定的最大内存（maxmemory 参数）时的淘汰策略。

*   noeviction（默认）不淘汰直接返回错误；
*   参数前缀是 volatile 和 allkeys，表示淘汰范围是有寿命 key 还是所有 key；
*   参数后缀是 ttl,lru,lfu,random，表示根据存活时间、最近最少使用、随机。

**lru：**最近最少使用。底层是双向链表（因为经常要移动元素），链表首部是最常使用元素，尾部是最少使用元素，每次刚访问的数据会移动到链表首部，刚添加的数据也会添加到链表首部。超出 maxmemory 会淘汰链表尾部元素，它最长时间没有被使用。

**lfu：**经常最少使用，随机采样淘汰最旧 key。Redis 会记录每个数据的最近一次访问的时间戳。内存超限后随机采样 N 个 key（通过 maxmemory_samples 配置，默认是 5），然后淘汰掉最旧的 key，若淘汰后内存依然超出限制，则继续采样淘汰。

**lru 为什么双向链表？**

使用双向链表主要是因为经常要移动元素，每次新访问元素移动到链表首部，该元素原位置的前后驱结点需要重连，用单链表无法实现。

![](<assets/1740030354876.png>)

**标准回答**

Redis 有如下两种过期策略：

**惰性删除：**客户端访问一个 key 的时候，Redis 会先检查它的过期时间，如果发现过期就立刻删除这个 key。

**定期删除：**Redis 会将设置了**过期时间的 key** 放到一个独立的**字典**中，并对该字典进行**每秒 10 次的过期扫描**， 过期扫描不会遍历字典中所有的 key，而是采用了一种简单的**贪心策略**。该策略的删除逻辑如下：

1. 从过期字典中随机选择 20 个 key；

2. 删除这 20 个 key 中已过期的 key；

3. 如果已过期 key 的比例超过 25%，则重复步骤 1。

**超出最大内存淘汰策略：**

当写入数据将导致**超出最大内存** maxmemory 限制时，Redis 会采用 maxmemory-policy 所指定的策略进行数据淘汰，该策略一共包含 8 种选项：noeviction、volatile-lru、volatile-lfu、volatile-ttl、volatile-random、allkeys-lru、allkeys-lfu、allkeys-random

其中除了 **noeviction 直接返回错误**之外，筛选键的方式分为 volatile 和 allkeys 两种，**volatile 前缀**代表从设置了**过期时间的键中淘汰**数据，**allkeys 前缀**代表从**所有的键中淘汰**数据**。**关于**后缀**，**ttl**（time to live）代表选择**存活时间最小**的键，**random** 代表**随机选择键**，需要我们额外关注的是 lru 和 lfu 后缀，它们分别代表采用**最近最少使用 lru**（Least Recently Used）算法和**访问次数最低 lfu（Least Frequently Used）**算法来淘汰数据。因为 allkeys 是筛选所有的键，所以不存在 ttl，余下三个后缀二者都有，lfu 算法是再 Redis4 版本才提出来的。

**加分回答**

**LRU**（Least Recently Used）是按照**最近最少使用**原则来筛选数据，即最不常用的数据会被筛选出来

- 标准 LRU：把所有的数据组成一个链表，表头和表尾分别表示 MRU 和 LRU 端，即最常使用端和最少使用端。刚被访问的数据会被移动到 MRU 端，而新增的数据也是刚被访问的数据，也会被移动到 MRU 端。当链表的空间被占满时，它会删除 LRU 端的数据。

- 近似 LRU：Redis 会记录每个数据的最近一次访问的时间戳（LRU）。Redis 执行写入操作时，若发现内存超出 maxmemory，就会执行一次近似 LRU 淘汰算法。近似 LRU 会随机采样 N 个 key，然后淘汰掉最旧的 key，若淘汰后内存依然超出限制，则继续采样淘汰。可以通过 maxmemory_samples 配置项，设置近似 LRU 每次采样的数据个数，该配置项的默认值为 5。

LRU 算法的不足之处在于，若一个 key 很少被访问，只是刚刚偶尔被访问了一次，则它就被认为是热点数据，短时间内不会被淘汰。

LFU 算法正式用于解决上述问题，**LFU（Least Frequently Used）**是 Redis4 新增的淘汰策略，它根据 key 的最近访问频率进行淘汰。LFU 在 LRU 的基础上，为每个数据增加了一个**计数器**，来统计这个数据的访问次数。当使用 LFU 策略淘汰数据时，首先会根据数据的访问次数进行筛选，把**访问次数最低的数据淘汰出内存**。如果两个数据的访问次数相同，LFU 再比较这两个数据的访问时间，把访问时间更早的数据淘汰出内存。

### 15、Redis 事务是否满足 ACID？

**Redis 的事务：**

*   **实现方式：**MULTI（开启事务，将命令都放进队列里），EXEC（执行事务），DISCARD（取消事务，清空队列）。
*   **不支持回滚：**在语法正确的情况下，Redis 事务一定会执行成功。只有语法错误时才会导致事务失败，而语法问题应该在开发时就避免，所以为了提高性能，Redis 事务不支持回滚。事务是一个原子操作，要么全部执行，要么全不执行。
*   **不完全满足 ACID 特性：**Redis 只满足隔离性和持久性，不满足原子性和一致性。
    *   **原子性：**事务的所有操作，要么全部成功，要么全部失败。Redis 不满足原子性，单个 Redis 命令的执行是原子性的，但事务失败后无法回滚。
    *   **一致性：**事务前后，数据库的约束没有被破坏，保持前后一致。Redis 连约束这个概念都没有。
    *   **隔离性：**操作同一资源的并发事务之间相互隔离，不会互相干扰。Redis 满足隔离性，因为 redis server 是单线程的，串行化执行事务，肯定是满足隔离性的。
    *   **持久性：**事务的结果最终一定会持久化到数据库，宕机等故障也无法影响。Redis 在开启 aof 并指定立刻持久化命令时，满足持久性。rdb 模式会丢失部分数据，不满足持久性。

### 16、如何排查 Redis 中的慢查询？

 **慢查询原因：**

*   **大 key 导致淘汰耗时长：**Redis 实例里存了大 key（string 类型值大于 10kb、其他类型元素个数超过 5000 个）。大 key 在申请内存和释放内存时，都比较耗时。
    *   **解决办法：**传输类瘦身（去除冗余字段、@JsonProperty 缩短字段名）、Redis 4.0 开启懒释放机制 (lazyfree-lazy-user-del) 使删除 key 在后台进行。
*   **内存上限导致写时数据淘汰：**Redis 实例设置了内存上限 maxmemory，并且内容已满，导致每次写数据时都要淘汰数据，从而影响查询性能。
    *   **解决办法：**加大 maxmemory 和服务器内存。
*   **开启内存大页导致 CopyOnWrite 耗时：**操作系统常规分配的内存页是 2KB，开启内存大页后就支持分配 2M 的内存页。Redis 在 bgsave 时如果有更改请求，主进程不会立刻改数据（防止子线程写 rdb 时混乱），而会采用 CopyOnWrite(写时复制) 技术拷贝一份待更改数据到内存大页（如果开启了的话）里，再进行更改。拷贝过程会耗费内存和性能。
    *   **解决办法：**关闭了内存大页，将只拷贝到 2KB 的常规内存页。
*   **内存不足导致 swap：**内存不足时，操作系统会通过 swap 机制将内存中部分数据 swap 到磁盘上进行读写，磁盘读写性能远不如内存。
    *   **解决办法：**加大服务器内存。
*   **网络带宽过载：**Redis 的瓶颈是内存大小和网络带宽，网络过载直接导致 Redis 读写性能差。
    *   **解决办法：**提高网络带宽、排除不必要的网络 IO。
*   **集中过期：**定期删除策略占用内存和性能导致查询变慢。Redis 采用惰性 + 定期的过期淘汰策略，如果大量 key 过期，Redis 会不断重复用贪心算法打捞删除 key，直到过期比例低于 25%。
    *   **解决办法：**过期时间加随机值、Redis 4.0 开启 lazy-free 机制。

**慢查询解决步骤：**

1.  **慢查询报警：**监控工具（如普罗米修斯 + Grafana）监控到慢查询报警；
2.  **检查慢查询日志：**慢查询阈值：slowlog-log-slower-than，默认 10ms。慢查询日志存储记录的最大数量：slowlog-max-len；
3.  **排查大 key：**bigkeys 命令查看各类型最大的 key
4.  **排查服务器、配置原因：**检查服务器内存量和带宽负载、Redis 最大内存、大 key、操作系统是否开启了内存大页