**目录**

[1、QPS是多少？](#1%E3%80%81QPS%E6%98%AF%E5%A4%9A%E5%B0%91%EF%BC%9F)

[1.5、RT是多少，分布式锁超时时间是多少，Sentinel降级RT是多少？](#1.5%E3%80%81RT%E6%98%AF%E5%A4%9A%E5%B0%91%EF%BC%8C%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81%E8%B6%85%E6%97%B6%E6%97%B6%E9%97%B4%E6%98%AF%E5%A4%9A%E5%B0%91%EF%BC%8CSentinel%E9%99%8D%E7%BA%A7RT%E6%98%AF%E5%A4%9A%E5%B0%91%EF%BC%9F)

[2、数据量](#2%E3%80%81%E6%95%B0%E6%8D%AE%E9%87%8F)

[3、JMeter是怎么进行压测的？](#JMeter%E6%98%AF%E6%80%8E%E4%B9%88%E8%BF%9B%E8%A1%8C%E5%8E%8B%E6%B5%8B%E7%9A%84%EF%BC%9F)

[4、高并发架构设计思路](#%E9%AB%98%E5%B9%B6%E5%8F%91%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%E6%80%9D%E8%B7%AF)

[5、百万高并发抢券业务设计思路](#%E5%A6%82%E6%9E%9C%E8%AE%BF%E9%97%AE%E9%87%8F%E6%89%A9%E5%A4%A7%E5%8D%81%E5%80%8D%EF%BC%8C%E5%A6%82%E4%BD%95%E6%89%A9%E5%AE%B9)

[6、秒杀超卖问题](#6%E3%80%81%E7%A7%92%E6%9D%80%E8%B6%85%E5%8D%96%E9%97%AE%E9%A2%98)

[7、如果访问量扩大十倍，如何扩容](#6%E3%80%81%E5%A6%82%E6%9E%9C%E8%AE%BF%E9%97%AE%E9%87%8F%E6%89%A9%E5%A4%A7%E5%8D%81%E5%80%8D%EF%BC%8C%E5%A6%82%E4%BD%95%E6%89%A9%E5%AE%B9)

[8、如何进行分库分表、数据迁移？](#%E5%A6%82%E4%BD%95%E8%BF%9B%E8%A1%8C%E5%88%86%E5%BA%93%E5%88%86%E8%A1%A8%E3%80%81%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%EF%BC%9F)

[9、如果将百万级别数据库里的数据进行迁移？](#%E5%A6%82%E6%9E%9C%E5%B0%86%E7%99%BE%E4%B8%87%E7%BA%A7%E5%88%AB%E6%95%B0%E6%8D%AE%E5%BA%93%E9%87%8C%E7%9A%84%E6%95%B0%E6%8D%AE%E8%BF%9B%E8%A1%8C%E8%BF%81%E7%A7%BB%EF%BC%9F)

[10、你们是怎么监控整个系统的？](#%E4%BD%A0%E4%BB%AC%E6%98%AF%E6%80%8E%E4%B9%88%E7%9B%91%E6%8E%A7%E6%95%B4%E4%B8%AA%E7%B3%BB%E7%BB%9F%E7%9A%84%EF%BC%9F)

[11、日志是怎么做的？规范是什么？](#%E6%97%A5%E5%BF%97%E6%98%AF%E6%80%8E%E4%B9%88%E5%81%9A%E7%9A%84%EF%BC%9F%E8%A7%84%E8%8C%83%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F)

[12、前后端分离项目怎么解决跨域问题？](#%E5%89%8D%E5%90%8E%E7%AB%AF%E5%88%86%E7%A6%BB%E9%A1%B9%E7%9B%AE%E6%80%8E%E4%B9%88%E8%A7%A3%E5%86%B3%E8%B7%A8%E5%9F%9F%E9%97%AE%E9%A2%98%EF%BC%9F)

[13、给第三方提供接口，如何规避安全问题](#%E7%BB%99%E7%AC%AC%E4%B8%89%E6%96%B9%E6%8F%90%E4%BE%9B%E6%8E%A5%E5%8F%A3%EF%BC%8C%E5%A6%82%E4%BD%95%E8%A7%84%E9%81%BF%E5%AE%89%E5%85%A8%E9%97%AE%E9%A2%98)

[14、接口如何保证幂等性？](#%E6%8E%A5%E5%8F%A3%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E5%B9%82%E7%AD%89%E6%80%A7%EF%BC%9F)

[15、怎么提高接口性能？](#%E6%80%8E%E4%B9%88%E6%8F%90%E9%AB%98%E6%8E%A5%E5%8F%A3%E6%80%A7%E8%83%BD%EF%BC%9F)

[16、有哪些分布式ID策略？](#%E6%9C%89%E5%93%AA%E4%BA%9B%E5%88%86%E5%B8%83%E5%BC%8FID%E7%AD%96%E7%95%A5%EF%BC%9F)

[17、Code Review是怎么做的？](#Code%20Review%E6%98%AF%E6%80%8E%E4%B9%88%E5%81%9A%E7%9A%84%EF%BC%9F)

[18、你们的开发模型是敏捷开发还是devops？](#16%E3%80%81%E4%BD%A0%E4%BB%AC%E7%9A%84%E5%BC%80%E5%8F%91%E6%A8%A1%E5%9E%8B%E6%98%AF%E6%95%8F%E6%8D%B7%E5%BC%80%E5%8F%91%E8%BF%98%E6%98%AFdevops%EF%BC%9F)

[19、什么是to B？什么是to C？](#19%E3%80%81%E4%BB%80%E4%B9%88%E6%98%AFto%20B%EF%BC%9F%E4%BB%80%E4%B9%88%E6%98%AFto%20C%EF%BC%9F)

[20、MySQL根据状态字段统计数据，状态字段会经常变](#20%E3%80%81MySQL%E6%A0%B9%E6%8D%AE%E7%8A%B6%E6%80%81%E5%AD%97%E6%AE%B5%E7%BB%9F%E8%AE%A1%E6%95%B0%E6%8D%AE%EF%BC%8C%E7%8A%B6%E6%80%81%E5%AD%97%E6%AE%B5%E4%BC%9A%E7%BB%8F%E5%B8%B8%E5%8F%98)

[21、哔哩哔哩在线人数是怎么统计？](#21%E3%80%81%E5%93%94%E5%93%A9%E5%93%94%E5%93%A9%E5%9C%A8%E7%BA%BF%E4%BA%BA%E6%95%B0%E6%98%AF%E6%80%8E%E4%B9%88%E7%BB%9F%E8%AE%A1%EF%BC%9F)

[22、6升和5升杯子，量出3升水](#22%E3%80%816%E5%8D%87%E5%92%8C5%E5%8D%87%E6%9D%AF%E5%AD%90%EF%BC%8C%E9%87%8F%E5%87%BA3%E5%8D%87%E6%B0%B4)

[23、设计一个定时任务](#23%E3%80%81%E8%AE%BE%E8%AE%A1%E4%B8%80%E4%B8%AA%E5%AE%9A%E6%97%B6%E4%BB%BB%E5%8A%A1)

[24、从网上下载东西，然后解析存到数据库的线程模型怎么设计](#24%E3%80%81%E4%BB%8E%E7%BD%91%E4%B8%8A%E4%B8%8B%E8%BD%BD%E4%B8%9C%E8%A5%BF%EF%BC%8C%E7%84%B6%E5%90%8E%E8%A7%A3%E6%9E%90%E5%AD%98%E5%88%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B%E6%80%8E%E4%B9%88%E8%AE%BE%E8%AE%A1)

--

### 1、QPS是多少？

> tp99：99%的请求耗时在100ms以内。
> 
> 并发数=qps\*rt。例如qps1000，平均响应时间是0.1s，则并发数100
> 
> qps：每秒请求数
> 
> rt：请求的响应时间，单位s
> 
> tps：每秒事务数

-   **MySQL瓶颈：**单个 MySQL 的每秒写入在 4000 QPS 左右，超过这个数字，MySQL 的 I/O 时延会剧量增长。
-   **Redis瓶颈：**Redis 单分片的写入瓶颈在 2w 左右，读瓶颈在 10w 左右；官方给出的报告综合8w左右。
-   **Nginx：**单机QPS瓶颈30w。一般不会成为系统瓶颈。**并发连接数：**官方测试支持5万并发连接。实际生产环境能到2-3万并发连接数。淘宝tengine团队说测试结果是“24G内存机器上，处理并发请求可达200万”。
-   **RabbitMQ：**单机QPS在万级别。
-   **Tomcat：**单机QPS瓶颈三四千。**并发连接数：**默认最大并发数是150，瓶颈一般是300-400并发数。

平时QPS只有三四百，早上7-9点高峰期能到八百，双十一等最高峰期qps到一千五六。加了sentinel限流。

Redis主从3台服务器、MySQL主从3台服务器，客诉单、申诉单、催收单服务各3台Tomcat服务器，RabbitMQ是1台服务器，sentinel是1台服务器。

### 1.5、RT是多少，分布式锁超时时间是多少，Sentinel降级RT是多少？

**RT：**

-   100ms为优良
-   500ms为及格
-   1000ms以上为不可忍受

**客诉单提交接口RT大概400ms左右。**

分布式锁超时时间：5s（考虑RT）。

**降级规则：**RT 10s，时间窗口30s。即RT超过10s时，接下来这个方法将在接下来的30s时间窗口里保持熔断。

![](https://i-blog.csdnimg.cn/blog_migrate/a67340b252a18d49acdbe514a85e1448.png)

> **流控规则：**QPS最大3000，warm up
> 
> ![](https://i-blog.csdnimg.cn/blog_migrate/a5ef1ff14956f55c9976e4a1efec2d8b.png)

### 2、数据量

-   客诉单：700w
-   记录表：每张表300w，11张表一共3000w，通过hash切分进行分表。
-   催收单：100w
-   申诉单：100w

### 3、JMeter是怎么进行压测的？

1.  添加线程组，设置线程数、循环次数；
2.  添加请求路径、协议、参数；
3.  查看结果树：每个请求路径、方式、响应结果
4.  查看汇总报告：请求数、TP99（90%请求在多少ms内完成）、TP95、响应时间中位数

实际的使用资源，一般是压测数据的 1.5 倍，我们需要保证线上有部分资源冗余以应对突发的流量增长。

### 4、高并发架构设计思路

画架构图，核心思想是分而治之，具体方法是缓存和消息。

-   **需求拆解：**思考有哪些表；我们需要有客诉单表、记录表、催收单表、申诉单表等表；
-   **QPS分析：**平时并发只有八九十，早上高峰期，7-9点高并发，qps到**三四百**。双十一等场景QPS最高能到一千左右，加了sentinel限流。
-   **数据库（考虑瓶颈）：**因为客诉单等信息需要持久化，所以选用常用关系型数据库MySQL。MySQL单机瓶颈4000 QPS，一主二从加上各种优化的话能应付系统六千QPS，但是双十一等高峰期就顶不住了需要sentinel限流。
-   **表、索引设计：**单表数据量到达千万级就会极大程度影响查询效率，要考虑水平拆分。
-   **缓存（考虑瓶颈）：**Redis缓存客诉单、投诉类型等信息。Redis单分片写瓶颈2w，读瓶颈10w，一主二从的话应付系统五六千的请求绰绰有余。
    -   **缓存和数据库一致性：**延时双删方案、异步监听+可靠消息删除方案
    -   **本地缓存：**引入本地缓存可以降低Redis压力，减少Redis超时请求的比例；需要注意，引入本地缓存后需要定时任务将最新的数据刷新到本地缓存
-   **消息队列：**因为会用到延时队列，所以选用RabbitMQ，一方面异步提高性能，例如落库后发消息同步es；另一方面被投诉方三天还不处理会被客服受理强制执行，所以需要延时队列。
-   **负载均衡：**用Nginx负载均衡，Nginx单机瓶颈50w QPS，不会成为系统瓶颈。
-   **系统框架选择：**Springboot+Nacos+OpenFeign+Sentinel+RabbitMQ+MySQL+Redis。
-   **考虑安全和性能问题：**考虑超额扣减库存、参数校验、权限校验、重复发券校验、线程安全、事务粒度和回滚方案、幂等性、性能瓶颈、MySQL,Redis,JVM调优、优惠券过期时间设置和到期自动删除。要尽量把不耗时的业务放前面来抵挡大部分请求。
-   **设计业务流程：**冻结运单、生成模板、举证文字、图片、落库客诉单表、MQ落库ES、落库记录表、外呼表。提交客诉单时幂等性检测用户id，保证只提交一个客诉单。
-   **服务治理：**
    -   **监控与报警。**对于一些核心接口的监控、稳定性、重要数据，以及系统 CPU、内存等的监控，我们会在 Grafana 上建立对应的可视化图表，在春节活动期间，实时观测 Grafana 仪表盘，以保证能够最快观测到系统异常。同时，对于一些异常情况，我们还有完善的报警机制，从而能够第一时间感知到系统的异常。
    -   **资源隔离。**因为我们服务都是部署在 docker 集群中的，因此为了保证服务的高可用，服务部署的集群资源尽量分布在不同的物理区域上，以避免由集群导致的服务不可用。
    -   **sentinel解决服务雪崩问题：**
        -   **限流。**实际业务场景下，客诉单服务会被一些上游服务（例如客服服务）所调用，因此，合理的对这些上游服务进行限流，也是保证优惠券系统本身稳定性必不可少的一环。
        -   **线程隔离：**调用者在调用服务提供者时，给每个调用的请求分配独立线程池，出现故障时，最多消耗这个线程池内资源，避免把调用者的所有资源耗尽。
        -   **熔断降级：**调用方加入断路器，统计对服务提供者的调用，如果调用失败比例过高，则熔断该业务，不允许访问该服务提供者。熔断后降级访问备胎方法。例如有些网站做的不好，直接服务雪崩完全崩溃，例如知乎。有些网站就可用性高，崩溃时常常是你无法评论、没法下单、没法联系客服、没法投诉，但是正常页面的浏览和视频播放是可以的，例如哔哩哔哩，这就保证了高可用。
        -   **超时设置：**超过500ms的请求拒绝。
-   **压测：**
    -   找到 MySQL 一主的写瓶颈、读瓶颈
    -   找到 Redis 单分片写瓶颈、读瓶颈
    -   实际的使用资源，一般是压测数据的 1.5 倍，我们需要保证线上有部分资源冗余以应对突发的流量增长。
-   **效果：**系统在高峰期6w QPS 的请求下，请求成功率达到 99.9%以上，系统监控正常。双十一期间，该客诉服务承载了庞大流量，期间未出现异常，圆满完成高并发场景下的物流调度客诉任务。

### 5、百万高并发抢券业务设计思路

1.  需求拆解（思考需要哪些表）
2.  存储方案：数据库、Redis、本地
3.  选择服务器数量：根据QPS和数据库缓存库Tomcat瓶颈选择服务器数量
4.  选择缓存一致性方案
5.  MQ异步解耦
6.  考虑性能和安全问题：考虑超额扣减库存、参数校验、权限校验、重复发券校验、线程安全、事务粒度和回滚方案、性能瓶颈、MySQL,Redis,JVM调优、优惠券过期时间设置和到期自动删除。要尽量把不耗时的业务放前面来抵挡大部分请求。
7.  设计业务流程：
    1.  库存刷缓存：活动发布之前把数据库里优惠券库存数量都刷入Redis里，别等到秒杀时候再刷缓存，降低数据库压力。数据库单机写瓶颈4000 QPS，Redis单机写瓶颈2w QPS。
    2.  定时任务发券：防止重复发券、保证顺序性防止超发。
    3.  业务校验：
    4.  扣减优惠券数量：
    5.  发MQ记录表落库：知道给哪些用户、什么时间发券了。
8.  监控报警；
9.  服务治理：Sentinel限流、熔断降级、超时时间设置。

### 6、秒杀超卖问题

超卖问题：两个线程同时获取到库存为1，都扣一次库存，导致库存被扣到-1。超卖问题归根结底是扣减操作没有保证原子性。原子性就是说一个线程只能获取到库存扣减前或扣减后的库存值，不能获取扣减中的库存值。

解决办法：分布式锁（乐观锁、Redis）保证库存增减的原子性。

悲观锁方案：不建议，性能差。

### 7、如果访问量扩大十倍，如何扩容

网关直接多部署 10 倍的机器即可，前面的 Nginx 做会负载均衡，把流量均分发给各个网关机器

数据库横向扩容很麻烦，可以考虑给单个数据库部署的机器提高配置，32核 128G 高配物理机，每秒钟抗几千请求问题不大

### 8、如何进行分库分表、数据迁移？

**概念：**

-   只分表：单表数据量大，读写出现瓶颈，这个表所在的库还可以支撑未来几年的增长。
-   只分库：整个数据库读写出现性能瓶颈，将整个库拆开。
-   分库分表：单表数据量大，所在库也出现性能瓶颈，就要既分库又分表。
-   垂直拆分：把字段分开。例如spu表的pic字段特别长，建议把这个pic字段拆到另一个表（同库或不同库）。
-   水平拆分：把记录分开。例如表数据量到达百万，我们拆成四张20万的表。

![](https://i-blog.csdnimg.cn/blog_migrate/25010180387362fa5c337928c1707e49.png)

 **拆分原则：**

| 数据量增长情况 | 数据表类型 | 优化核心思想 |
| --- | --- | --- |
| 数据量为千万级，是一个相对**稳定**的数据量 | 状态表 | 能不拆就不拆读需求水平扩展 |
| 数据量为千万级，可能达到**亿级**或者更高 | 流水表 | 业务拆分，面向分布式存储设计 |
| 数据量为千万级，可能达到**亿级**或者更高 | 流水表 | 设计数据统计需求存储的分布式扩展 |
| 数据量为千万级，不应该有这么多的数据 | 配置表 | 小而简，避免大一统 |

**分库分表步骤：**

-   **MySQL调优：**数据量能稳定在千万级，近几年不会到达亿级，其实是不用着急拆的，先尝试MySQL调优，优化读写性能。
    
-   **目标评估：**评估拆几个库、表，举例: 当前20亿，5年后评估为100亿。分几个表? 分几个库?解答:一个合理的答案，1024个表，16个库按1024个表算，拆分完单表200万，5年后为1000万.1024个表\*200w≈100亿
    
-   **表拆分：**
    
    -   **业务层拆分：**混合业务拆分为独立业务、冷热分离
        
    -   **数据层拆分：**
        
        -   **按日期拆分：**这种使用方式比较普遍，尤其是按照日期维度的拆分，其实在程序层面的改动很小，但是扩展性方面的收益很大。
            
            -   日维度拆分，如test\_20191021
            -   月维度拆分,如test\_201910
            -   年维度拆分,如test\_2019
        -   **按主键范围拆分：**例如【1,200w】主键在一个表，【200w，400w】主键在一个表。优点是单表数据量可控。缺点是流量无法分摊，写操作集中在最后面的表。
            
        -   **中间表映射：**表随意拆分，引入中间表记录查询的字段值，以及它对应的数据在哪个表里。优点是灵活。确定是引入中间表让流程变复杂。
            
        -   **hash切分：**sharding\_key%N。优点是数据分片均匀，流量分摊。缺点是扩容需要迁移数据，跨节点查询问题。
            
        -   **按分区拆分：**hash,range等方式。不建议，因为数据其实难以实现水平扩展。
            
-   **sharding\_key（分表字段）选择：**尽量选择查询频率最高的字段，然后根据表拆分方式选择字段。
    
-   **代码改造：**修改代码里的查询、更新语句，以便让其适应分库分表后的情况。
    
-   **数据迁移：**最简单的就是停机迁移，复杂点的就是不停机迁移，要考虑增量同步和全量同步的问题。
    
    -   **增量同步：**老库迁移到新库期间，新增删改命令的落库不能出错
        
        -   同步双写：同步写新库和老库；
        -   **异步双写（推荐）：** 写老库，监听binlog异步同步到新库
        -   中间件同步工具：通过一定的规则将数据同步到目标库表
    -   **全量同步：**老库到新库的数据迁移，要控制好迁移效率，解决增量数据的一致性。
        
        -   **定时任务查老库写新库**
        -   使用中间件迁移数据
-   **数据一致性校验和补偿：**假设采用异步双写方案，在迁移完成后，逐条对比新老库数据，一致则跳过，**不一致则补偿：**
    
    -   新库存在，老库不存在：新库删除数据
    -   新库不存在，老库存在：新库插入数据
    -   新库存在、老库存在：比较所有字段，不一致则将新库更新为老库数据
-   **灰度切读：**灰度发布指黑（旧版本）与白（新版本）之间，让一些用户继续用旧版本，一些用户开始用新版本，如果用户对新版本没什么意见，就逐步把所有用户迁移到新版本，实现平滑过渡发布。**原则：**
    
    -   有问题及时切回老库
    -   灰度放量先慢后快，每次放量观察一段时间
    -   支持灵活的规则：门店维度灰度、百 (万)分比灰度
-   **停老用新：**下线老库，用新库读写。
    

### 9、如果将百万级别数据库里的数据进行迁移？

-   **数据迁移：**最简单的就是停机迁移，复杂点的就是不停机迁移，要考虑增量同步和全量同步的问题。
    
    -   **增量同步：**老库迁移到新库期间，新增删改命令的落库不能出错
        
        -   同步双写：同步写新库和老库；
        -   **异步双写（推荐）：** 写老库，监听binlog异步同步到新库
        -   中间件同步工具：通过一定的规则将数据同步到目标库表
    -   **全量同步：**老库到新库的数据迁移，要控制好迁移效率，解决增量数据的一致性。
        
        -   **定时任务查老库写新库**
        -   使用中间件迁移数据
-   **数据一致性校验和补偿：**假设采用异步双写方案，在迁移完成后，逐条对比新老库数据，一致则跳过，**不一致则补偿：**
    
    -   新库存在，老库不存在：新库删除数据
    -   新库不存在，老库存在：新库插入数据
    -   新库存在、老库存在：比较所有字段，不一致则将新库更新为老库数据
-   **灰度切读：**灰度发布指黑（旧版本）与白（新版本）之间，让一些用户继续用旧版本，一些用户开始用新版本，如果用户对新版本没什么意见，就逐步把所有用户迁移到新版本，实现平滑过渡发布。**原则：**
    
    -   有问题及时切回老库
    -   灰度放量先慢后快，每次放量观察一段时间
    -   支持灵活的规则：门店维度灰度、百 (万)分比灰度
-   **停老用新：**下线老库，用新库读写。
    

### 10、你们是怎么监控整个系统的？

普罗米修斯+Grafana，监控springboot的QPS等、监控MySQL、Redis、监控jvm。普罗米修斯监控得到的数据是文本形式；Grafana是可视化工具，对普罗米修斯的数据进行展示统计报警。

**普罗米修斯安装步骤：**

1.  普罗米修斯官网下载解压；配置ip和端口；
2.  启动，发现默认只监控自己这台节点（Endpoint）；
3.  下载解压配置exporter：官网下载解压Linux、MySQL等组件的exporter，分别配置ip和端口，然后这些exporter会暴露出url为http://ip:host/metrics的http服务，普罗米修斯就可以对它进行监控。
4.  启动，发现可以看见很多远程服务器节点（Endpoint），运行状态；
5.  点击这些节点可以查看监控的所有指标

 ![](https://i-blog.csdnimg.cn/blog_migrate/006cbf411d92283c473480d6fc8f1673.png)

![](https://i-blog.csdnimg.cn/blog_migrate/dad84428a6456c25225602f01e98b50f.png)

**Grafana安装：**

1.  下载安装解压启动，配置端口域名用户名密码；
2.  网页添加普罗米修斯数据源，输入url；
3.  导入MySQL、JVM等仪表盘

### 11、日志是怎么做的？规范是什么？

**Log4j：**是一个完整的**日志库**。需要导入log4j依赖，在yml配置输出到控制台的输出格式（日期、日志级别（info,error,warn,debug,trace）、全限定类名、内容、回车）等信息，配置输出到文件的存储路径、文件名、日期格式等信息。可以通过Log4j的配置文件灵活配置日志的记录格式、记录级别、输出格式等，而不需要修改已有的日志记录代码。

**Slf4j：**是日志库的**统一规范接口**。需要导入lombok依赖。接口用来统一打印日志，忽略日志的具体实现方法，即使我们的系统换了一个日志源，不需要我们去更改代码。

**日志规范：**

-   **日志级别：**选择恰当的日志级别；error（严重错误，对业务影响大）、warn（对业务影响不大，主要给开发看）、info（关键参数、调用时间）、debug（关键逻辑里面的运行时数据）、trace（最详细信息，只记录在文件不打印在控制台）
-   **入参出参：**要打印方法的入参、出参
-   **日志格式：**选择合适的日志格式，时间精确到ms，日志级别、线程名、类名
-   **分支首行：**分支首行打印日志；
-   **低日志级别要开关判断：**trace/debug前要log.isDebugEnabled()、log.isTraceEnabled()
-   **SLF4J：**不能直接使用日志系统（Log4j、Logback）中的 API，而是使用日志框架SLF4J中的API。
-   **不要拼接：**建议使用参数占位{}，而不是用+拼接。因为字符串拼接有一定的性能损耗。
-   **配置开启异步：**日志最终会输出到文件或者其它输出流中的，IO性能会有要求的。如果异步，就可以显著提升IO性能。
-   **不要使用e.printStackTrace()：**改成log.error("你的程序有异常啦",e);
    -   **防止日志混乱：**e.printStackTrace()打印出的堆栈日志跟业务代码日志是交错混合在一起的，通常排查异常日志不太方便。
    -   **性能问题：**printStackTrace()方法会生成大量的字符串对象，对系统性能有一定的影响。
-   **异常要输出整个e：**log.error('你的程序有异常啦', e);而不是e.getMessage()
-   **不要同时抛异常和打印异常：**会导致栈信息打印两次。
-   **不同类型日志文件分离：**根据业务模块分离日志、根据日志级别分离日志。
-   **日志尽可能完整但不要重复：**有利于排查定位问题。

### 12、前后端分离项目怎么解决跨域问题？

**跨域：**指的是浏览器不能执行其他网站的脚本，它是由浏览器的同源策略造成的，是浏览器对javascript施加的安全限制。

**同源策略：**是指协议，域名，端口都要相同，其中有一个不同都会产生跨域问题。

**解决跨域：**nginx反向代理为同一域、@CrossOrigin、CorsWebFilter

-   **Nginx：**生产环境下，使用nginx反向代理为同一域。使用Nginx反向代理，不同地址、端口都被同一个域名反向代理了，这就是同一域了。这种方法在开发时没法用。
-   **@CrossOrigin：**在支持跨域的方法上添加@CrossOrigin注解。
-   **CorsWebFilter：**网关模块新建配置类，将CorsWebFilter注册为Bean，Bean内部新建CorsConfiguration对象，设置允许跨域的请求头、请求方式、url、是否允许携带cookie等信息，然后将CorsConfiguration对象作为CorsWebFilter对象的参数返回。CORS是跨域资源共享，用于解决后端跨域问题。
-   **网关全局跨域：**spring.cloud.gateway.routes.globalcors.corsConfigurations配置允许跨域的请求头、请求方式、url、是否允许携带cookie等信息

```java
@Configuration
public class CorsConfiguration{
 
    @Bean
    public CorsWebFilter corsWebFilter(){
        UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource();
 
        CorsConfiguration corsConfiguration= new CorsConfiguration();
        //1、配置跨域
        // 允许跨域的请求头
        corsConfiguration.addAllowedHeader("*");
        // 允许跨域的请求方式
        corsConfiguration.addAllowedMethod("*");
        // 允许跨域的请求来源
        corsConfiguration.addAllowedOriginPattern("*");
//注释的这句会报错。因为当allowCredentials为真时，allowedorigin不能包含特殊值"*"，因为不能在"访问-控制-起源“响应头中设置该值。
        //corsConfiguration.addAllowedOrigin("*");//这句会报错
        // 是否允许携带cookie跨域
        corsConfiguration.setAllowCredentials(true);
 
        // 任意url都要进行跨域配置，两个*号就是可以匹配包含0到多个/的路径
        source.registerCorsConfiguration("/**",corsConfiguration);
        return new CorsWebFilter(source);
 
    }
}
```

### 13、给第三方提供接口，如何规避安全问题

-   **数据脱敏掩码：**手机号、身份证号、密码等敏感信息要用md5或bcrypt进行掩码，虽然只有开发和运维会看到日志，但还是需要防一下。
-   **参数校验：**JSR303校验，实体类注解@NotNull(message,groups)等，接口参数注解@Valid或@Validated({AddGroup.class})
-   **接口幂等性：**数据库唯一约束、乐观锁、Redis唯一序列号。
-   **数据加密：**日常数据传输使用https就够了，如果安全性要求高，例如要需要传输密码，密码使用rsa非对称加密。rsa：导入依赖后，创建两个RSA对象，构造参数分别是公钥和私钥，公钥RSA进行加密，私钥RSA解密。
-   **时间戳超时机制：**用户每次请求都带上当前时间的时间戳timestamp，服务端接收到timestamp后，解密、验签通过后，与服务器当前时间进行比对，如果时间差大于一定时间(比如3分钟)，则认为该请求无效。防止恶意请求，不断发请求搞垮你的系统。
-   **限流：**例如sentinel限流。
-   **黑名单机制、白名单机制**

> 对称加密：加密解密使用同一把密钥，优点是速度快，常见算法des和aes。
> 
> 非对称加密：加密时采用公钥，解密时采用私钥。公钥私钥成对存在，公钥加密后只有对应的私钥才能解密，私钥加密后只有对应的公钥才能解密。常见算法rsa。缺点是性能开销。

### 14、接口如何保证幂等性？

同时发多次请求，结果一样，也就是说只有一个请求会成功。

-   **前端防抖处理：**防止用户告诉点击提交按钮导致订单重复提交。解决办法：前端对这个点击事件进行处理，控制在100ms内同一用户只有第一次点击提交按钮会提交成功。前端治标不治本，例如一些恶意重复提交的情况，一般会用程序避开前端的页面控制，比如说用爬虫程序，这就需要后端来限制接口重复提交，构建第二道防线。
-   **数据库约束：**比如唯一约束，主键。同一个主键不可能两次都插入成功。不推荐因为适用范围太窄，只适用于保存数据库前就已经设置好主键并且每次主键一样的情况下。缺点是只适用于新增场景。
-   **乐观锁：**数据库表中增加一个版本字段，更新时判断是否等于某个版本。例如重复提交时判断数据库发现版本已被改变就不提交了。不推荐，因为要查数据库，给数据库压力，临时的操作我们尽量在缓存库里操作，降低数据库压力。
-   **Redis存唯一序列号（推荐）：**点击“进入订单”时就生成随机uuid作为token，存Redis"业务前缀+用户id"--->token，携带token发“提交订单”请求，提交订单方法原子性验删前端传来的token和Redis根据查的token。验证删除成功后才正式执行提交业务，验证失败代表完全不是一个订单，删除失败代表有其他同订单线程已经验删成功了。
-   **验证码：**让用户每次提交时输入验证码，提交后校验前后端验证码实现幂等性。

### 15、怎么提高接口性能？

-   **通用：**Redis缓存、MQ、MySQL调优、多线程、硬件（网络带宽、加内存）
-   **本地缓存：**如果不是强一致的话，可以尝试加本地缓存（例如Spring的caffeine）。因为本地缓存加在服务器上，不同服务器更新频率不同可能导致本地缓存的数据不一致，所以只适用于对一致性要求不高的场景。
-   **Nginx开启gzip：**压缩JSON文件，提高传输效率，传输到浏览器后再进行解压。Nginx默认不开启，要手动修改配置文件开启，并设置文件超过多大时压缩、压缩哪些文件类型。
-   **传输类瘦身：**
    -   去除冗余字段，只查需要用到的字段。
    -   通过@JsonProperty给vo属性名重命名为一个字符或两个字符大小。

### 16、有哪些分布式ID策略？

**自增策略的缺点：**

-   **自增ID回溯**：存在自增ID回溯的问题，可靠性不高，这个问题直到最新版本的MySQL 8.0才修复。自增ID回溯：生成id前执行 last\_insert\_id() 函数获取上一条记录的id为x，如果删除上一条记录并重启MySQL，再次执行函数得到的id是x-1，产生回溯了。
-   **安全性不高**：对外暴露的接口可以非常**容易猜测对应的信息**。比如：/User/1/这样的接口，可以非常容易猜测用户ID的 值为多少，总用户数量有多少，也可以非常容易地通过接口进行数据的爬取。
-   **性能差**：自增ID的性能较差，需要在数据库服务器端生成。
-   **需要额外执行函数得知自增值，高并发时锁竞争影响性能**：业务还需要额外执行一次类似 **last\_insert\_id()** 的函数才能知道刚才插入的自增值，这需要多一次的 网络交互。在海量并发的系统中，多1条SQL，就多一次性能上的开销。而且在高并发场景下锁竞争获取自增值会极大的影响性能，即使它是原子性的。
-   **分库分表、数据迁移时，自增不再适用。**

**UUID：**分布式唯一，缺点是不有序。

【时间低位-时间中位-时间高位-UUID版本-时钟序列-MAC地址】。

MySQL8.0开始支持有序UUID，可以通过uuid\_to\_bin函数实现。原理是将时间低位和时间高位的顺序更换。

**雪花算法（建议）：**分布式id算法，有序。与系统时间有关，如果修改了系统时间会导致主键重复。

【代表正数的固定值0-时间戳-机器ID-服务ID-序号】

### 17、Code Review是怎么做的？

每个迭代会和整个团队开一次代码审查会议。我们坐在会议室，每一个开发者展示并解释着他最近写的一段困难的代码。其他开发者尝试寻找着潜在的缺陷，发表评论，给出如何改进代码的建议。我感觉这种做法适用于的一种情况：当整个团队都没有代码审查的经验时，让把每个人聚起来，一起做代码审查，这样弄几次之后，可能会帮助每个人理解代码审查的目标和意义。

> **其他Code Review方法：**
> 
> -   **pull request：**项目的每一个版本开发需要建对应的一个版本号例如：v1.0.0 ，然后每个人需要基于这个分支建自己的小分支例如：v1.0.0\_name1 ，这样的话你就可以在v1.0.0\_name1分支上开发了，当想把自己分支的代码提交到当前项目的分支v1.0.0 中的时候，就可以用 Pull Request 来提交，然后code review的管理者就可以看到有 pull request请求，然后管理者可以查看提交的内容，可以评论，和通过。当管理者通过后，你的提交就自动进入了v1.0.0分支里面了。
> -   **瞬时的代码审查：**也称为结对编程(pair programming)。 发生在结对编程的情景中。当一个开发者在敲键盘写代码的同时，另一个开发者盯着代码，注意着代码中潜在的问题，并在此过程中给出提升代码质量的建议。结对编程适用于两个有相似经验水平的开发者处理复杂的业务问题的情况。
> -   **同步的代码审查：**也称为即时(over-the-shoulder)代码审查 一个开发者独自编写代码，当她写完代码后，立即找代码审查者进行审查。审查者来到开发者的桌前，看着同一块屏幕，一起审查、讨论和改进代码。当审查者不清楚这个任务的目标时，这种代码审查类型会很有效果。
> -   **异步的代码审查：**也称为有工具支持的(tool-assisted)代码审查 开发者在写完代码后，让这些代码对审查者可见，然后开始她的下一个任务。当审查者有时间了，他会在自己的桌子上按自己的时间表进行代码审查。他而不需要当面和开发者沟通，而是用工具写一些评论。在完成审查后，那些工具会把评论和需要的改动通知给开发者。开发者就会根据评论改进代码。异步的代码审查应该作为每一个专业开发团队的默认选项。
> -   **迭代会议审查：**每个迭代会和整个团队开一次代码审查会议。我们坐在会议室，每一个开发者展示并解释着他最近写的一段困难的代码。其他开发者尝试寻找着潜在的缺陷，发表评论，给出如何改进代码的建议。我感觉这种做法适用于的一种情况：当整个团队都没有代码审查的经验时，让把每个人聚起来，一起做代码审查，这样弄几次之后，可能会帮助每个人理解代码审查的目标和意义。

### 18、你们的开发模型是敏捷开发还是devops？

**瀑布模型：**期望整个系统从开始到结束都是一个整体，所有的周期活动只进行一次。也就是只做一次需求获取(一次就获取到所有的需求)，一次需求分析(一次将所有的需求分析完整)，一次设计等等。**流程：**

-   **需求设计：**大概花了六个月吧，首先是产品和项目经历对接甲方确定需求文档，大概一周时间；半个月；
-   **概要设计：**然后我们后端小组立项、分析功能模块、编写概要设计文档，包括模块名、子功能、每个增删改查接口，设计表；半个月；
-   **详细设计：**各功能的接口，包括请求路径、请求参数、响应值等；半个月；
-   **编码阶段：**架构师搭建工程、选择技术、我们根据各自负责模块开发，每半个月为一个小周期完成需求；三个月；
-   **全链路测试：**半个月；
-   **预交付：**跟甲方拉扯需求，一般是前端修改；半个月；

增量模型：增量模型将整个系统结构化的拆成几个增量（功能模块）-- 比如3个，每一个完整的周期完成一个增量，有几个增量就重复几个周期。

**迭代开发模型：**在迭代开发中，将系统的开发工作划分成一个个迭代，不要求一次行完成整个系统的开发（相对于瀑布开发而言）。迭代开发目前有两种，一种是在**每个迭代中​使用瀑布模型​**。另一种是每一个迭代中完成软件开发阶段的某一个阶段。

敏捷开发：如果只是从开发的核心阶段来看，敏捷开发就是迭代开发。然而实际上迭代开发是敏捷开发的一部分，指导开发阶段的那一部分。敏捷开发还包括了迭代开发不包含的：开卡、结卡、TDD、Pair programming、review、feedback等等实践活动。敏捷开发在迭代开发的基础上，通过引入一些活动来达到团队自循环、自我完善，从而对团队本身进行迭代，以提高团队的开发效率、质量、体验等。

### 19、什么是to B？什么是to C？

-   to B：为企业提供服务。例如员工管理系统是给企业用的、淘宝商家版是给商家用的。
-   to C：为消费者提供服务。例如淘宝给用户卖商品、抖音给用户卖流量

### 20、MySQL根据状态字段统计数据，状态字段会经常变

### 20.1、哔哩哔哩播放量怎么统计？

**哔哩哔哩方案：**用户同时点击两个窗口，只算一次观看：Redis的set类型，将每个观看用户的ip地址加到set里。然后定时任务每隔1小时把数据刷到数据库里。这个应该也是哔哩哔哩的大致方案，他们只考虑播放量，而不考虑平均播放时长，导致垃圾营销号的视频播放量都很高。

**视频播放时长记次方案：**每次播放时都新增一个延时队列，ttl是视频的51%时间，到时间检查一下用户是否还在观看（可以查用户同一ip浏览记录）。

### 21、哔哩哔哩在线人数是怎么统计？

这个数据经常变，而且不敏感，不建议直接数据库字段统计。

用户同时点击两个窗口，只算一次观看：Redis的set类型，将每个观看用户的ip地址加到set里，并设置视频时长为过期时间。然后定时任务每隔1小时把数据刷到数据库里。设置1小时主要考虑到这个数据不敏感。

用户同时点击两个窗口，算两次观看：不太建议，有刷单的风险，刷单的视频比真正有质量的视频在线人数高，得到更多推广。而且在线人数多上了热门，而不是付费上热门，刷单成本比付费成本低，所以不建议。

### 22、6升和5升杯子，量出3升水

记A为5升杯子，B为6升杯子。核心是要取到B里4升。

1.  A满，倒入B。此时A0，B5
2.  A满，倒入B。此时A4，B6
3.  倒掉B，A倒入B。此时A0，B4
4.  A满，倒入B。此时A3，B2

### 23、设计一个定时任务

### 24、从网上下载东西，然后解析存到数据库的线程模型怎么设计

多线程下载解析，然后countdownlatch或者CompletableFuture的allOf()后对数据进行整合，存储

### 为什么要写博客？

1.  费曼学习法：最好的学习方法是输出，将知识像小学生一样教授给读者；
2.  知识迭代
3.  相信记忆是不可靠的
4.  掌握生产资料：我们公司写的代码产权是属于公司的，即使给你奖金，你离职后跟你也一点关系都没有了，人这一生，还是需要积累一些属于自己的东西的；
5.  快速回顾

### 25、待添加

1、情景题：如果一个外卖配送单子要发布，现在有200个骑手都想要接这一单，如何保证只有一个骑手接到单子？  
2、场景题：美团首页每天会从10000个商家里面推荐50个商家置顶，每个商家有一个权值，你如何来推荐？第二天怎么更新推荐的商家？  
可以借鉴下stackoverflow，视频网站等等的推荐算法。  
3、场景题：微信抢红包问题  
悲观锁，乐观锁，存储过程放在mysql数据库中。  
4、场景题：1000个任务，分给10个人做，你怎么分配，先在纸上写个最简单的版本，然后优化。  
全局队列，把1000任务放在一个队列里面，然后每个人都是取，完成任务。  
分为10个队列，每个人分别到自己对应的队列中去取务。  
5、场景题：保证发送消息的有序性，消息处理的有序性。  
6、如何把一个文件快速下发到100w个服务器  
7、给每个组分配不同的IP段，怎么设计一种结构使的快速得知IP是哪个组的?  
8、10亿个数，找出最大的10个。  
建议一个大小为10的小根堆。  
9、有几台机器存储着几亿淘宝搜索日志，你只有一台2g的电脑，怎么选出搜索热度最高的十个搜索关键词？  
10、分布式集群中如何保证线程安全？  
11、给个淘宝场景，怎么设计一消息队列？  
12、10万个数，输出从小到大？  
先划分成多个小文件，送进内存排序，然后再采用多路归并排序。  
13、有十万个单词，找出重复次数最高十个？